{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a45e091-04b9-482c-ba4e-cd68a43b6f02",
   "metadata": {},
   "source": [
    "# For read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62414c4-39ca-4df2-b1e0-0c1f5e349569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python-ng in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: avro==1.10.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: kafka-python in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: selenium in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chardet in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kafka-python-ng\n",
    "%pip install --upgrade avro==1.10.0 kafka-python\n",
    "%pip install selenium\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8269421-4a9e-4bfe-9bda-6c898004b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "from avro import schema\n",
    "from avro.io import DatumWriter, BinaryEncoder\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pprint  # Import pprint for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb029712-1f4b-421d-a6cb-cca6f3f92205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-07 22:48:39--  https://github.com/nnatchy/DSDE_Project/raw/main/2018_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip [following]\n",
      "--2024-05-07 22:48:40--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6913340 (6.6M) [application/zip]\n",
      "Saving to: ‘2018.zip’\n",
      "\n",
      "2018.zip            100%[===================>]   6.59M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:41 (53.6 MB/s) - ‘2018.zip’ saved [6913340/6913340]\n",
      "\n",
      "--2024-05-07 22:48:41--  https://github.com/nnatchy/DSDE_Project/raw/main/2019_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip [following]\n",
      "--2024-05-07 22:48:41--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7328143 (7.0M) [application/zip]\n",
      "Saving to: ‘2019.zip’\n",
      "\n",
      "2019.zip            100%[===================>]   6.99M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:42 (55.1 MB/s) - ‘2019.zip’ saved [7328143/7328143]\n",
      "\n",
      "--2024-05-07 22:48:42--  https://github.com/nnatchy/DSDE_Project/raw/main/2020_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip [following]\n",
      "--2024-05-07 22:48:43--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7393768 (7.1M) [application/zip]\n",
      "Saving to: ‘2020.zip’\n",
      "\n",
      "2020.zip            100%[===================>]   7.05M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:44 (54.8 MB/s) - ‘2020.zip’ saved [7393768/7393768]\n",
      "\n",
      "--2024-05-07 22:48:44--  https://github.com/nnatchy/DSDE_Project/raw/main/2021_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip [following]\n",
      "--2024-05-07 22:48:45--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7509824 (7.2M) [application/zip]\n",
      "Saving to: ‘2021.zip’\n",
      "\n",
      "2021.zip            100%[===================>]   7.16M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:46 (54.8 MB/s) - ‘2021.zip’ saved [7509824/7509824]\n",
      "\n",
      "--2024-05-07 22:48:46--  https://github.com/nnatchy/DSDE_Project/raw/main/2022_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip [following]\n",
      "--2024-05-07 22:48:47--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7154957 (6.8M) [application/zip]\n",
      "Saving to: ‘2022.zip’\n",
      "\n",
      "2022.zip            100%[===================>]   6.82M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:48 (51.9 MB/s) - ‘2022.zip’ saved [7154957/7154957]\n",
      "\n",
      "--2024-05-07 22:48:48--  https://github.com/nnatchy/DSDE_Project/raw/main/2023_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip [following]\n",
      "--2024-05-07 22:48:48--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7874655 (7.5M) [application/zip]\n",
      "Saving to: ‘2023.zip’\n",
      "\n",
      "2023.zip            100%[===================>]   7.51M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 22:48:50 (57.9 MB/s) - ‘2023.zip’ saved [7874655/7874655]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "years = range(2018, 2024)  # Years from 2018 to 2023\n",
    "for year in years:\n",
    "    # Construct the URL\n",
    "    url = f\"https://github.com/nnatchy/DSDE_Project/raw/main/{year}_test.zip\"\n",
    "    # url = f\"https://github.com/nnatchy/DSDE_Project/raw/main/{year}.zip\"\n",
    "    # Construct the wget command to download and rename the file directly\n",
    "    !wget {url} -O {year}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d12fcb-3c79-4043-a8fc-9966c873a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to print the json with the indent=4\n",
    "def jprint(data):\n",
    "  print(json.dumps(data,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc61ac2-4d02-4bf8-a6d7-10eb4623ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ./2018.zip to ./2018/\n",
      "Extracted ./2019.zip to ./2019/\n",
      "Extracted ./2020.zip to ./2020/\n",
      "Extracted ./2021.zip to ./2021/\n",
      "Extracted ./2022.zip to ./2022/\n",
      "Extracted ./2023.zip to ./2023/\n"
     ]
    }
   ],
   "source": [
    "def process_files(year_range, base_path):\n",
    "    batch_years = []\n",
    "    for year in year_range:\n",
    "        # Determine the directory pattern based on the year\n",
    "        year_directory = f\"{base_path}/{year}/\" if year == 2018 else f\"{base_path}/{year}/\"\n",
    "\n",
    "        # Ensure the year directory exists and create if not\n",
    "        os.makedirs(year_directory, exist_ok=True)\n",
    "\n",
    "        # Check for zip files in the base path and unzip them to the year directory\n",
    "        zip_file_path = os.path.join(base_path, f'{year}.zip')\n",
    "        if os.path.exists(zip_file_path):\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(year_directory)\n",
    "                print(f\"Extracted {zip_file_path} to {year_directory}\")\n",
    "\n",
    "by = process_files(range(2018, 2024), \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3a63f-99c5-46f3-8c63-2643586bd75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./2018/2018 copy/201800010\", 'r') as file:\n",
    "#     json_data = json.load(file)\n",
    "# abstracts_info = json_data.get(\"abstracts-retrieval-response\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13b753-2bae-4b26-bec1-e611f824cfd9",
   "metadata": {},
   "source": [
    "# Function for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83efd3c1-3485-48b6-b91b-6b65367e0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find how many author are in this paper\n",
    "def num_author_group(head_data):\n",
    "  num = 0\n",
    "  for author in head_data:\n",
    "    if int(author['seq']) > num:\n",
    "      num = int(author['seq'])\n",
    "\n",
    "  return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b589cf7-bb40-41cf-a6ae-e27876599c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_head_data(bibrecord_data):\n",
    "    # process author\n",
    "    author_groups = bibrecord_data[\"head\"][\"author-group\"]\n",
    "    if isinstance(author_groups, dict):\n",
    "        author_groups = [author_groups]  \n",
    "    \n",
    "    head_output_data = {\"author_groups\": []}\n",
    "\n",
    "    for author in author_groups:\n",
    "        affi = author.get(\"affiliation\", {})\n",
    "        org = affi.get(\"organization\", [])\n",
    "        if isinstance(org, dict):  \n",
    "            organization_names = [org[\"$\"]]\n",
    "        elif isinstance(org, list):  \n",
    "            organization_names = [o[\"$\"] for o in org]\n",
    "        else:\n",
    "            organization_names = []  \n",
    "    \n",
    "        affi_info = {\n",
    "            \"affiliation_id\": affi.get(\"@afid\", \"\"),\n",
    "            \"dpt_id\": affi.get(\"@dptid\", \"\"),\n",
    "            \"country\": affi.get(\"country\", \"\"),\n",
    "            \"organization\": organization_names  \n",
    "        }\n",
    "    \n",
    "        authors = author.get(\"author\", [])\n",
    "        if isinstance(authors, dict):  \n",
    "            authors = [authors]\n",
    "    \n",
    "        for person in authors:\n",
    "            author_info = {\n",
    "                \"indexed-name\": person.get(\"preferred-name\", {}).get(\"ce:indexed-name\", \"\"),\n",
    "                \"seq\": person.get(\"@seq\", \"\"),\n",
    "                \"auid\": person.get(\"@auid\", \"\"),\n",
    "                \"affiliation\": affi_info  # Include affiliation info\n",
    "            }\n",
    "            head_output_data[\"author_groups\"].append(author_info)\n",
    "    head_output_data[\"enhancement\"] = []\n",
    "\n",
    "    # process classifiaction group\n",
    "    if \"enhancement\" in bibrecord_data[\"head\"] and \"classificationgroup\" in bibrecord_data[\"head\"][\"enhancement\"]:\n",
    "        classifications = bibrecord_data[\"head\"][\"enhancement\"][\"classificationgroup\"].get(\"classifications\", [])\n",
    "\n",
    "        if isinstance(classifications, dict):\n",
    "            classifications = [classifications] \n",
    "    \n",
    "        for classification in classifications:\n",
    "            if classification[\"@type\"] == \"SUBJABBR\":  \n",
    "                if isinstance(classification.get(\"classification\"), (list, dict)):\n",
    "                    if isinstance(classification[\"classification\"], list):\n",
    "                        all_classifications = [item.get(\"$\", item) if isinstance(item, dict) else item for item in classification[\"classification\"]]\n",
    "                    else:  \n",
    "                        all_classifications = [classification[\"classification\"].get(\"$\", classification[\"classification\"])]\n",
    "                else:  \n",
    "                    all_classifications = [classification[\"classification\"]]\n",
    "    \n",
    "                class_info = {\n",
    "                    \"type\": classification[\"@type\"],\n",
    "                    \"classifications\": all_classifications\n",
    "                }\n",
    "                head_output_data[\"enhancement\"].append(class_info)\n",
    "\n",
    "    # Extract source information\n",
    "    head_output_data[\"source\"] = {\n",
    "        \"publication_date\": bibrecord_data[\"head\"][\"source\"][\"publicationdate\"],\n",
    "    }\n",
    "\n",
    "    \n",
    "    return head_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102820f9-1971-4910-91dc-fa388c53b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_citation_count(DOI):\n",
    "    \n",
    "    API_KEY = \"8a4d62cf82cf68382f5f55a658354336\"\n",
    "    BASE_URL = \"http://api.elsevier.com/content/search/scopus\"\n",
    "    \n",
    "    headers = {\n",
    "        \"X-ELS-APIKey\": API_KEY\n",
    "    }\n",
    "    \n",
    "    query_url = f\"{BASE_URL}?query=DOI({DOI})&field=citedby-count\"\n",
    "    response = requests.get(query_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        cited_by_count = data[\"search-results\"][\"entry\"][0][\"citedby-count\"]\n",
    "        # print(f\"The document with DOI {DOI} has been cited by {cited_by_count} times in Scopus.\")\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "\n",
    "    return cited_by_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4f5d16-082a-4c1f-9136-3f195ddfdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tail_data(bibrecord_data):\n",
    "    # Ensure 'tail' is a dictionary before proceeding\n",
    "    tail_info = bibrecord_data.get(\"tail\", {})\n",
    "\n",
    "    bibliography_output = {\n",
    "        \"refcount\": \"\",\n",
    "        \"references\": []\n",
    "    }\n",
    "\n",
    "    if not tail_info:  # Check if tail_info is empty or None\n",
    "        return bibliography_output\n",
    "\n",
    "    bibliography = tail_info.get(\"bibliography\", {})\n",
    "    bibliography_output[\"refcount\"] = bibliography.get(\"@refcount\", \"0\")\n",
    "\n",
    "    # Handle references\n",
    "    references = bibliography.get(\"reference\", [])\n",
    "    if not isinstance(references, list):\n",
    "        references = [references] if references else []\n",
    "\n",
    "    for ref in references:\n",
    "        reference_info = {\n",
    "            \"id\": ref.get(\"@id\", \"\"),\n",
    "            \"ref_fulltext\": ref.get(\"ref-fulltext\", \"\"),\n",
    "            \"ref_text\": ref.get(\"ce:source-text\", \"\"),\n",
    "            \"ref_info\": {},\n",
    "            \"ref_authors\": [],\n",
    "            \"ref_authors_count\": \"\",\n",
    "            \"ref_collab\": []\n",
    "        }\n",
    "\n",
    "        ref_info = ref.get(\"ref-info\", {})\n",
    "        reference_info[\"ref_info\"] = {\n",
    "            \"ref_publicationyear\": ref_info.get(\"ref-publicationyear\", {}).get(\"@first\", \"\"),\n",
    "            \"ref_title\": ref_info.get(\"ref-title\", {}).get(\"ref-titletext\", \"Title Not Available\"),\n",
    "            \"ref_sourcetitle\": ref_info.get(\"ref-sourcetitle\", \"\")\n",
    "        }\n",
    "\n",
    "        # Process authors and collaborations\n",
    "        ref_authors = ref_info.get(\"ref-authors\", {})\n",
    "        authors = ref_authors.get(\"author\", [])\n",
    "        if not isinstance(authors, list):\n",
    "            authors = [authors] if authors else []\n",
    "        reference_info[\"ref_authors\"] = [author.get(\"ce:indexed-name\", \"\") for author in authors]\n",
    "        reference_info[\"ref_authors_count\"] = len(reference_info[\"ref_authors\"])\n",
    "\n",
    "        collaborations = ref_authors.get(\"collaboration\", [])\n",
    "        if not isinstance(collaborations, list):\n",
    "            collaborations = [collaborations] if collaborations else []\n",
    "        reference_info[\"ref_collab\"] = [{\"collaboration_name\": collab.get(\"ce:text\", \"\")} for collab in collaborations]\n",
    "\n",
    "        bibliography_output[\"references\"].append(reference_info)\n",
    "\n",
    "    return bibliography_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa68600-aa41-416d-8dc1-046672b46cd3",
   "metadata": {},
   "source": [
    "# Function for get the required Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f7b6ab-3fa2-4539-8206-9d85b2c60a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_feature(data, file_name):\n",
    "    output_data = {\n",
    "        \"id\": str(file_name),\n",
    "        \"publicDate\": \"\",\n",
    "        \"source\": 1,\n",
    "        \"coAuthorship\": 0,\n",
    "        \"citationCount\": 0,\n",
    "        \"refCount\": 0,\n",
    "        \"Class\": []\n",
    "    }\n",
    "\n",
    "    bibrecord_data = data['item']['bibrecord']\n",
    "    \n",
    "    head_data = process_head_data(bibrecord_data)\n",
    "\n",
    "    # find publication date\n",
    "    date = head_data['source']['publication_date']\n",
    "    output_data['publicDate'] = date['day'] + '/' + date['month'] + '/' + date['year']\n",
    "\n",
    "    # find num authorship\n",
    "    output_data['coAuthorship'] = num_author_group(head_data['author_groups'])\n",
    "\n",
    "    # find citation count\n",
    "    item_info = bibrecord_data['item-info']\n",
    "    if \"ce:doi\" not in item_info['itemidlist']:\n",
    "        output_data['citationCount'] = None\n",
    "    else :\n",
    "        doi = item_info['itemidlist']['ce:doi']\n",
    "        output_data['citationCount'] = get_citation_count(doi)\n",
    "\n",
    "    # find the references count\n",
    "    tail_data = process_tail_data(bibrecord_data)\n",
    "    output_data['refCount'] = tail_data['refcount']\n",
    "\n",
    "    # get the class\n",
    "    enhancement_data = head_data['enhancement']\n",
    "    for item in enhancement_data:\n",
    "        if item['type'] == 'SUBJABBR':\n",
    "            for subject in item['classifications']:\n",
    "                output_data['Class'].append(subject)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9975b51-74ed-434d-afbd-eeb4b943ce8b",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e2e279-7387-469a-9d12-b3ae849dfdee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'id': '201800282', 'publicDate': '15/11/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '29', 'refCount': '89', 'Class': ['ENER', 'PHYS']}\n",
      "Sent: {'id': '201800276', 'publicDate': '17/11/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '11', 'refCount': '18', 'Class': ['CHEM', 'BIOC', 'AGRI']}\n",
      "Sent: {'id': '201800044', 'publicDate': '11/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '76', 'refCount': '60', 'Class': ['ENVI', 'CENG', 'MATE', 'ENER']}\n",
      "Sent: {'id': '201800249', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '9', 'refCount': '39', 'Class': ['EART', 'AGRI']}\n",
      "Sent: {'id': '201800043', 'publicDate': '12/12/2018', 'source': 1, 'coAuthorship': 2303, 'citationCount': '59', 'refCount': '101', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800271', 'publicDate': '20/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '53', 'refCount': '21', 'Class': ['COMP']}\n",
      "Sent: {'id': '201800285', 'publicDate': '14/11/2018', 'source': 1, 'coAuthorship': 1, 'citationCount': '5', 'refCount': '16', 'Class': ['AGRI', 'ENVI']}\n",
      "Sent: {'id': '201800088', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 32, 'citationCount': '23', 'refCount': '107', 'Class': ['PHYS', 'EART']}\n",
      "Sent: {'id': '201800075', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': None, 'refCount': '', 'Class': ['VETE']}\n",
      "Sent: {'id': '201800247', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '8', 'refCount': '48', 'Class': ['MATE', 'ENGI']}\n",
      "Sent: {'id': '201800081', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '8', 'refCount': '22', 'Class': ['NEUR', 'MEDI']}\n",
      "Sent: {'id': '201800278', 'publicDate': '16/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '1', 'refCount': '7', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800086', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '0', 'refCount': '16', 'Class': ['ENER', 'ENGI', 'COMP']}\n",
      "Sent: {'id': '201800240', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '19', 'refCount': '46', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800072', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': None, 'refCount': '33', 'Class': ['VETE']}\n",
      "Sent: {'id': '201800019', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '0', 'refCount': '31', 'Class': ['BUSI', 'ECON', 'ENVI']}\n",
      "Sent: {'id': '201800026', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '2', 'refCount': '3', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800214', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '14', 'refCount': '23', 'Class': ['IMMU', 'VETE']}\n",
      "Sent: {'id': '201800213', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '79', 'refCount': '52', 'Class': ['CHEM']}\n",
      "Sent: {'id': '201800021', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '4', 'refCount': '17', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800028', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '3', 'refCount': '3', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800225', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 40, 'citationCount': '34', 'refCount': '27', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800017', 'publicDate': '20/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '119', 'refCount': '74', 'Class': ['ENVI', 'CENG', 'MATE', 'ENER']}\n",
      "Sent: {'id': '201800010', 'publicDate': '25/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '19', 'refCount': '43', 'Class': ['CHEM', 'PHYS', 'MATE']}\n",
      "Sent: {'id': '201800222', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '36', 'refCount': '47', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800073', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': None, 'refCount': '29', 'Class': ['VETE']}\n",
      "Sent: {'id': '201800241', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '53', 'refCount': '353', 'Class': ['NEUR']}\n",
      "Sent: {'id': '201800087', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '3', 'refCount': '16', 'Class': ['ENER', 'ENGI', 'COMP']}\n",
      "Sent: {'id': '201800080', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': None, 'refCount': '42', 'Class': ['VETE']}\n",
      "Sent: {'id': '201800246', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 12, 'citationCount': '23', 'refCount': '31', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800074', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 1, 'citationCount': None, 'refCount': '3', 'Class': ['VETE']}\n",
      "Sent: {'id': '201800279', 'publicDate': '16/11/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '1', 'refCount': '22', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800284', 'publicDate': '15/11/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '34', 'refCount': '23', 'Class': ['CHEM', 'MATE']}\n",
      "Sent: {'id': '201800270', 'publicDate': '21/11/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '22', 'refCount': '42', 'Class': ['CHEM', 'BIOC', 'ENVI']}\n",
      "Sent: {'id': '201800042', 'publicDate': '13/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '39', 'refCount': '48', 'Class': ['AGRI', 'NURS']}\n",
      "Sent: {'id': '201800089', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '0', 'refCount': '', 'Class': ['COMP', 'DECI', 'ENGI', 'PHYS']}\n",
      "Sent: {'id': '201800045', 'publicDate': '10/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '44', 'refCount': '54', 'Class': ['SOCI', 'COMP']}\n",
      "Sent: {'id': '201800277', 'publicDate': '16/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '0', 'refCount': '5', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800283', 'publicDate': '15/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '19', 'refCount': '43', 'Class': ['CHEM', 'MATE']}\n",
      "Sent: {'id': '201800248', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '11', 'refCount': '18', 'Class': ['ENGI', 'COMP']}\n",
      "Sent: {'id': '201800223', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '0', 'refCount': '4', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800011', 'publicDate': '24/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '6', 'refCount': '19', 'Class': ['COMP', 'DECI']}\n",
      "Sent: {'id': '201800029', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '0', 'refCount': '1', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800016', 'publicDate': '20/12/2018', 'source': 1, 'coAuthorship': 9, 'citationCount': '13', 'refCount': '49', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800224', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '22', 'refCount': '69', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800020', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '1', 'refCount': '11', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800212', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 13, 'citationCount': '52', 'refCount': '140', 'Class': ['BIOC']}\n",
      "Sent: {'id': '201800018', 'publicDate': '20/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '33', 'refCount': '41', 'Class': ['ENER', 'ENGI', 'ENVI', 'BUSI']}\n",
      "Sent: {'id': '201800215', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '22', 'refCount': '31', 'Class': ['DENT']}\n",
      "Sent: {'id': '201800027', 'publicDate': '19/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '0', 'refCount': '7', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800155', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '8', 'refCount': '39', 'Class': ['BIOC', 'IMMU']}\n",
      "Sent: {'id': '201800152', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '21', 'refCount': '22', 'Class': ['SOCI', 'ENER', 'ENVI']}\n",
      "Sent: {'id': '201800199', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '2', 'refCount': '11', 'Class': ['MATH', 'DECI']}\n",
      "Sent: {'id': '201800164', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 8, 'citationCount': '6', 'refCount': '3', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800190', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '22', 'refCount': '48', 'Class': ['CHEM', 'CENG', 'PHYS']}\n",
      "JSON Decode Error in file .DS_Store: Expecting value: line 1 column 1 (char 0)\n",
      "Sent: {'id': '201800197', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 9, 'citationCount': '25', 'refCount': '99', 'Class': ['EART']}\n",
      "Sent: {'id': '201800163', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '13', 'refCount': '37', 'Class': ['MATE', 'PHYS', 'ENGI', 'MATH']}\n",
      "Sent: {'id': '201800108', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '0', 'refCount': '15', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800137', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '5', 'refCount': '42', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800305', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 9, 'citationCount': '1', 'refCount': '32', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800302', 'publicDate': '02/11/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '3', 'refCount': '48', 'Class': ['CHEM', 'CENG']}\n",
      "Sent: {'id': '201800130', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 22, 'citationCount': '136', 'refCount': '174', 'Class': ['PHYS', 'EART']}\n",
      "Sent: {'id': '201800139', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '5', 'refCount': '3', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800106', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '3', 'refCount': '19', 'Class': ['PHAR', 'AGRI', 'MEDI']}\n",
      "Sent: {'id': '201800101', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 1, 'citationCount': None, 'refCount': '26', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800162', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '10', 'refCount': '16', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800196', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '5', 'refCount': '46', 'Class': ['BIOC', 'CHEM', 'PHYS']}\n",
      "Sent: {'id': '201800191', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '12', 'refCount': '54', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800165', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '38', 'refCount': '47', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800153', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 14, 'citationCount': '45', 'refCount': '67', 'Class': ['MEDI', 'NEUR']}\n",
      "Sent: {'id': '201800198', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 8, 'citationCount': '27', 'refCount': '9', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800154', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '7', 'refCount': '53', 'Class': ['ENVI']}\n",
      "Sent: {'id': '201800332', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '8', 'refCount': '27', 'Class': ['BIOC']}\n",
      "Sent: {'id': '201800100', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '0', 'refCount': '31', 'Class': ['MEDI', 'NURS']}\n",
      "Sent: {'id': '201800138', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '10', 'refCount': '13', 'Class': ['COMP', 'DECI']}\n",
      "Sent: {'id': '201800107', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': None, 'refCount': '17', 'Class': ['ENGI', 'COMP']}\n",
      "Sent: {'id': '201800131', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '15', 'refCount': '28', 'Class': ['CENG', 'BIOC', 'CHEM', 'COMP']}\n",
      "Sent: {'id': '201800303', 'publicDate': '02/11/2018', 'source': 1, 'coAuthorship': 6, 'citationCount': '8', 'refCount': '26', 'Class': ['CHEM', 'BIOC', 'AGRI']}\n",
      "Sent: {'id': '201800109', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '2', 'refCount': '', 'Class': ['BIOC']}\n",
      "Sent: {'id': '201800304', 'publicDate': '02/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '15', 'refCount': '71', 'Class': ['SOCI', 'ARTS', 'BUSI']}\n",
      "Sent: {'id': '201800136', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '14', 'refCount': '30', 'Class': ['COMP', 'ENGI']}\n",
      "Sent: {'id': '201800114', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '11', 'refCount': '', 'Class': ['MEDI', 'IMMU']}\n",
      "Sent: {'id': '201800326', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 2302, 'citationCount': '26', 'refCount': '85', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800319', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': None, 'refCount': '32', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800321', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': None, 'refCount': '10', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800113', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '9', 'refCount': '', 'Class': ['MEDI', 'IMMU']}\n",
      "Sent: {'id': '201800317', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '15', 'refCount': '38', 'Class': ['BIOC']}\n",
      "Sent: {'id': '201800125', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '13', 'refCount': '62', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800328', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 2302, 'citationCount': '103', 'refCount': '56', 'Class': ['PHYS']}\n",
      "Sent: {'id': '201800122', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '19', 'refCount': '10', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800310', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': None, 'refCount': '30', 'Class': ['CHEM', 'MATH', 'MATE', 'BIOC', 'PHYS']}\n",
      "Sent: {'id': '201800149', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '4', 'refCount': '37', 'Class': ['CENG']}\n",
      "Sent: {'id': '201800176', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '14', 'refCount': '42', 'Class': ['MEDI', 'BIOC']}\n",
      "Sent: {'id': '201800182', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 4, 'citationCount': '2', 'refCount': '26', 'Class': ['BIOC', 'MEDI']}\n",
      "Sent: {'id': '201800185', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '23', 'refCount': '39', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800171', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 11, 'citationCount': '25', 'refCount': '54', 'Class': ['BIOC']}\n",
      "Sent: {'id': '201800178', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 5, 'citationCount': '17', 'refCount': '26', 'Class': ['MEDI', 'DENT']}\n",
      "Sent: {'id': '201800147', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '5', 'refCount': '23', 'Class': ['DENT']}\n",
      "Sent: {'id': '201800140', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '7', 'refCount': '25', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800311', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 8, 'citationCount': '16', 'refCount': '72', 'Class': ['COMP']}\n",
      "Sent: {'id': '201800123', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 7, 'citationCount': '7', 'refCount': '23', 'Class': ['MEDI']}\n",
      "Sent: {'id': '201800124', 'publicDate': '01/12/2018', 'source': 1, 'coAuthorship': 12, 'citationCount': '7', 'refCount': '30', 'Class': ['MULT']}\n",
      "Sent: {'id': '201800316', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 3, 'citationCount': '7', 'refCount': '37', 'Class': ['COMP', 'DECI']}\n",
      "Sent: {'id': '201800329', 'publicDate': '01/11/2018', 'source': 1, 'coAuthorship': 2, 'citationCount': '30', 'refCount': '24', 'Class': ['ENER', 'ENVI']}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping empty file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m                 time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mprocess_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m producer\u001b[38;5;241m.\u001b[39mflush()\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mprocess_directory\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 31\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mchardet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/chardet/__init__.py:49\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(byte_str, should_rename_legacy)\u001b[0m\n\u001b[1;32m     47\u001b[0m     byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(byte_str)\n\u001b[1;32m     48\u001b[0m detector \u001b[38;5;241m=\u001b[39m UniversalDetector(should_rename_legacy\u001b[38;5;241m=\u001b[39mshould_rename_legacy)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/chardet/universaldetector.py:274\u001b[0m, in \u001b[0;36mUniversalDetector.feed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers\u001b[38;5;241m.\u001b[39mappend(MacRomanProber())\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prober \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprober\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m ProbingState\u001b[38;5;241m.\u001b[39mFOUND_IT:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m: prober\u001b[38;5;241m.\u001b[39mcharset_name,\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m: prober\u001b[38;5;241m.\u001b[39mget_confidence(),\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: prober\u001b[38;5;241m.\u001b[39mlanguage,\n\u001b[1;32m    279\u001b[0m         }\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/chardet/charsetgroupprober.py:70\u001b[0m, in \u001b[0;36mCharSetGroupProber.feed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prober\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mprober\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/chardet/utf8prober.py:68\u001b[0m, in \u001b[0;36mUTF8Prober.feed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coding_state \u001b[38;5;241m==\u001b[39m MachineState\u001b[38;5;241m.\u001b[39mSTART:\n\u001b[0;32m---> 68\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoding_sm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_charlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_mb_chars \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m ProbingState\u001b[38;5;241m.\u001b[39mDETECTING:\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/chardet/codingstatemachine.py:82\u001b[0m, in \u001b[0;36mCodingStateMachine.get_current_charlen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curr_byte_pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curr_state\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_charlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curr_char_len\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coding_state_machine\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import time\n",
    "import json\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer=lambda x: json.dumps(x).encode('utf-8'),\n",
    "    request_timeout_ms=60000,  # Increase timeout to 60 seconds\n",
    "    retry_backoff_ms=500,  # Increase backoff time between retries\n",
    ")\n",
    "\n",
    "# Initialize Kafka Producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer=lambda x: json.dumps(x).encode('utf-8'),\n",
    "    request_timeout_ms=60000,\n",
    "    retry_backoff_ms=500\n",
    ")\n",
    "\n",
    "def process_directory(base_path):\n",
    "    for year in range(2018, 2019):  # Example year range\n",
    "        year_path = os.path.join(base_path, str(year), f'{year} copy')\n",
    "        if os.path.isdir(year_path):\n",
    "            for file_name in os.listdir(year_path):\n",
    "                file_path = os.path.join(year_path, file_name)\n",
    "                \n",
    "                # Check if the file is not empty\n",
    "                if os.path.getsize(file_path) > 0:\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        raw_data = f.read()\n",
    "                        result = chardet.detect(raw_data)\n",
    "                        encoding = result['encoding']\n",
    "\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding=encoding) as file:\n",
    "                            json_data = json.load(file)\n",
    "                            abstracts_info = json_data.get(\"abstracts-retrieval-response\", {})\n",
    "                            data = get_all_feature(abstracts_info, file_name)\n",
    "                            producer.send(str(year), value=data).get(timeout=30)\n",
    "                            print(f\"Sent: {data}\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"JSON Decode Error in file {file_name}: {str(e)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to process file {file_name}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"Skipping empty file: {file_name}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "process_directory('./')\n",
    "\n",
    "producer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
