{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a45e091-04b9-482c-ba4e-cd68a43b6f02",
   "metadata": {},
   "source": [
    "# For read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c62414c4-39ca-4df2-b1e0-0c1f5e349569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python-ng in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: avro==1.10.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: kafka-python in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: selenium in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/pirayan/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kafka-python-ng\n",
    "%pip install --upgrade avro==1.10.0 kafka-python\n",
    "%pip install selenium\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8269421-4a9e-4bfe-9bda-6c898004b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "from avro import schema\n",
    "from avro.io import DatumWriter, BinaryEncoder\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pprint  # Import pprint for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb029712-1f4b-421d-a6cb-cca6f3f92205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-07 02:41:55--  https://github.com/nnatchy/DSDE_Project/raw/main/2018_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip [following]\n",
      "--2024-05-07 02:41:56--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6913340 (6.6M) [application/zip]\n",
      "Saving to: ‘2018.zip’\n",
      "\n",
      "2018.zip            100%[===================>]   6.59M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 02:41:57 (46.1 MB/s) - ‘2018.zip’ saved [6913340/6913340]\n",
      "\n",
      "--2024-05-07 02:41:57--  https://github.com/nnatchy/DSDE_Project/raw/main/2019_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip [following]\n",
      "--2024-05-07 02:41:58--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7328143 (7.0M) [application/zip]\n",
      "Saving to: ‘2019.zip’\n",
      "\n",
      "2019.zip            100%[===================>]   6.99M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 02:41:59 (49.1 MB/s) - ‘2019.zip’ saved [7328143/7328143]\n",
      "\n",
      "--2024-05-07 02:41:59--  https://github.com/nnatchy/DSDE_Project/raw/main/2020_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip [following]\n",
      "--2024-05-07 02:41:59--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7393768 (7.1M) [application/zip]\n",
      "Saving to: ‘2020.zip’\n",
      "\n",
      "2020.zip            100%[===================>]   7.05M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 02:42:00 (49.9 MB/s) - ‘2020.zip’ saved [7393768/7393768]\n",
      "\n",
      "--2024-05-07 02:42:01--  https://github.com/nnatchy/DSDE_Project/raw/main/2021_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip [following]\n",
      "--2024-05-07 02:42:01--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7509824 (7.2M) [application/zip]\n",
      "Saving to: ‘2021.zip’\n",
      "\n",
      "2021.zip            100%[===================>]   7.16M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 02:42:02 (52.8 MB/s) - ‘2021.zip’ saved [7509824/7509824]\n",
      "\n",
      "--2024-05-07 02:42:02--  https://github.com/nnatchy/DSDE_Project/raw/main/2022_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip [following]\n",
      "--2024-05-07 02:42:03--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7154957 (6.8M) [application/zip]\n",
      "Saving to: ‘2022.zip’\n",
      "\n",
      "2022.zip            100%[===================>]   6.82M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-05-07 02:42:04 (46.6 MB/s) - ‘2022.zip’ saved [7154957/7154957]\n",
      "\n",
      "--2024-05-07 02:42:04--  https://github.com/nnatchy/DSDE_Project/raw/main/2023_test.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip [following]\n",
      "--2024-05-07 02:42:05--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7874655 (7.5M) [application/zip]\n",
      "Saving to: ‘2023.zip’\n",
      "\n",
      "2023.zip            100%[===================>]   7.51M  45.9MB/s    in 0.2s    \n",
      "\n",
      "2024-05-07 02:42:06 (45.9 MB/s) - ‘2023.zip’ saved [7874655/7874655]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "years = range(2018, 2024)  # Years from 2018 to 2023\n",
    "for year in years:\n",
    "    # Construct the URL\n",
    "    url = f\"https://github.com/nnatchy/DSDE_Project/raw/main/{year}_test.zip\"\n",
    "    # Construct the wget command to download and rename the file directly\n",
    "    !wget {url} -O {year}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d12fcb-3c79-4043-a8fc-9966c873a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to print the json with the indent=4\n",
    "def jprint(data):\n",
    "  print(json.dumps(data,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc61ac2-4d02-4bf8-a6d7-10eb4623ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ./2018.zip to ./2018/\n",
      "Extracted ./2019.zip to ./2019/\n",
      "Extracted ./2020.zip to ./2020/\n",
      "Extracted ./2021.zip to ./2021/\n",
      "Extracted ./2022.zip to ./2022/\n",
      "Extracted ./2023.zip to ./2023/\n"
     ]
    }
   ],
   "source": [
    "def process_files(year_range, base_path):\n",
    "    batch_years = []\n",
    "    for year in year_range:\n",
    "        # Determine the directory pattern based on the year\n",
    "        year_directory = f\"{base_path}/{year}/\" if year == 2018 else f\"{base_path}/{year}/\"\n",
    "\n",
    "        # Ensure the year directory exists and create if not\n",
    "        os.makedirs(year_directory, exist_ok=True)\n",
    "\n",
    "        # Check for zip files in the base path and unzip them to the year directory\n",
    "        zip_file_path = os.path.join(base_path, f'{year}.zip')\n",
    "        if os.path.exists(zip_file_path):\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(year_directory)\n",
    "                print(f\"Extracted {zip_file_path} to {year_directory}\")\n",
    "\n",
    "by = process_files(range(2018, 2024), \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dad3a63f-99c5-46f3-8c63-2643586bd75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./2018/2018/201800010\", 'r') as file:\n",
    "#     json_data = json.load(file)\n",
    "# abstracts_info = json_data.get(\"abstracts-retrieval-response\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13b753-2bae-4b26-bec1-e611f824cfd9",
   "metadata": {},
   "source": [
    "# Function for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83efd3c1-3485-48b6-b91b-6b65367e0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find how many author are in this paper\n",
    "def num_author_group(head_data):\n",
    "  num = 0\n",
    "  for author in head_data:\n",
    "    if int(author['seq']) > num:\n",
    "      num = int(author['seq'])\n",
    "\n",
    "  return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b589cf7-bb40-41cf-a6ae-e27876599c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_head_data(bibrecord_data):\n",
    "    # process author\n",
    "    author_groups = bibrecord_data[\"head\"][\"author-group\"]\n",
    "    if isinstance(author_groups, dict):\n",
    "        author_groups = [author_groups]  \n",
    "    \n",
    "    head_output_data = {\"author_groups\": []}\n",
    "\n",
    "    for author in author_groups:\n",
    "        affi = author.get(\"affiliation\", {})\n",
    "        org = affi.get(\"organization\", [])\n",
    "        if isinstance(org, dict):  \n",
    "            organization_names = [org[\"$\"]]\n",
    "        elif isinstance(org, list):  \n",
    "            organization_names = [o[\"$\"] for o in org]\n",
    "        else:\n",
    "            organization_names = []  \n",
    "    \n",
    "        affi_info = {\n",
    "            \"affiliation_id\": affi.get(\"@afid\", \"\"),\n",
    "            \"dpt_id\": affi.get(\"@dptid\", \"\"),\n",
    "            \"country\": affi.get(\"country\", \"\"),\n",
    "            \"organization\": organization_names  \n",
    "        }\n",
    "    \n",
    "        authors = author.get(\"author\", [])\n",
    "        if isinstance(authors, dict):  \n",
    "            authors = [authors]\n",
    "    \n",
    "        for person in authors:\n",
    "            author_info = {\n",
    "                \"indexed-name\": person.get(\"preferred-name\", {}).get(\"ce:indexed-name\", \"\"),\n",
    "                \"seq\": person.get(\"@seq\", \"\"),\n",
    "                \"auid\": person.get(\"@auid\", \"\"),\n",
    "                \"affiliation\": affi_info  # Include affiliation info\n",
    "            }\n",
    "            head_output_data[\"author_groups\"].append(author_info)\n",
    "    head_output_data[\"enhancement\"] = []\n",
    "\n",
    "    # process classifiaction group\n",
    "    if \"enhancement\" in bibrecord_data[\"head\"] and \"classificationgroup\" in bibrecord_data[\"head\"][\"enhancement\"]:\n",
    "        classifications = bibrecord_data[\"head\"][\"enhancement\"][\"classificationgroup\"].get(\"classifications\", [])\n",
    "\n",
    "        if isinstance(classifications, dict):\n",
    "            classifications = [classifications] \n",
    "    \n",
    "        for classification in classifications:\n",
    "            if classification[\"@type\"] == \"SUBJABBR\":  \n",
    "                if isinstance(classification.get(\"classification\"), (list, dict)):\n",
    "                    if isinstance(classification[\"classification\"], list):\n",
    "                        all_classifications = [item.get(\"$\", item) if isinstance(item, dict) else item for item in classification[\"classification\"]]\n",
    "                    else:  \n",
    "                        all_classifications = [classification[\"classification\"].get(\"$\", classification[\"classification\"])]\n",
    "                else:  \n",
    "                    all_classifications = [classification[\"classification\"]]\n",
    "    \n",
    "                class_info = {\n",
    "                    \"type\": classification[\"@type\"],\n",
    "                    \"classifications\": all_classifications\n",
    "                }\n",
    "                head_output_data[\"enhancement\"].append(class_info)\n",
    "\n",
    "    \n",
    "    return head_output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "102820f9-1971-4910-91dc-fa388c53b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_citation_count(DOI):\n",
    "    \n",
    "    API_KEY = \"8a4d62cf82cf68382f5f55a658354336\"\n",
    "    BASE_URL = \"http://api.elsevier.com/content/search/scopus\"\n",
    "    \n",
    "    headers = {\n",
    "        \"X-ELS-APIKey\": API_KEY\n",
    "    }\n",
    "    \n",
    "    query_url = f\"{BASE_URL}?query=DOI({DOI})&field=citedby-count\"\n",
    "    response = requests.get(query_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        cited_by_count = data[\"search-results\"][\"entry\"][0][\"citedby-count\"]\n",
    "        # print(f\"The document with DOI {DOI} has been cited by {cited_by_count} times in Scopus.\")\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "\n",
    "    return cited_by_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b4f5d16-082a-4c1f-9136-3f195ddfdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tail_data(bibrecord_data):\n",
    "    # Ensure 'tail' is a dictionary before proceeding\n",
    "    tail_info = bibrecord_data.get(\"tail\", {})\n",
    "\n",
    "    bibliography_output = {\n",
    "        \"refcount\": \"\",\n",
    "        \"references\": []\n",
    "    }\n",
    "\n",
    "    if not tail_info:  # Check if tail_info is empty or None\n",
    "        return bibliography_output\n",
    "\n",
    "    bibliography = tail_info.get(\"bibliography\", {})\n",
    "    bibliography_output[\"refcount\"] = bibliography.get(\"@refcount\", \"0\")\n",
    "\n",
    "    # Handle references\n",
    "    references = bibliography.get(\"reference\", [])\n",
    "    if not isinstance(references, list):\n",
    "        references = [references] if references else []\n",
    "\n",
    "    for ref in references:\n",
    "        reference_info = {\n",
    "            \"id\": ref.get(\"@id\", \"\"),\n",
    "            \"ref_fulltext\": ref.get(\"ref-fulltext\", \"\"),\n",
    "            \"ref_text\": ref.get(\"ce:source-text\", \"\"),\n",
    "            \"ref_info\": {},\n",
    "            \"ref_authors\": [],\n",
    "            \"ref_authors_count\": \"\",\n",
    "            \"ref_collab\": []\n",
    "        }\n",
    "\n",
    "        ref_info = ref.get(\"ref-info\", {})\n",
    "        reference_info[\"ref_info\"] = {\n",
    "            \"ref_publicationyear\": ref_info.get(\"ref-publicationyear\", {}).get(\"@first\", \"\"),\n",
    "            \"ref_title\": ref_info.get(\"ref-title\", {}).get(\"ref-titletext\", \"Title Not Available\"),\n",
    "            \"ref_sourcetitle\": ref_info.get(\"ref-sourcetitle\", \"\")\n",
    "        }\n",
    "\n",
    "        # Process authors and collaborations\n",
    "        ref_authors = ref_info.get(\"ref-authors\", {})\n",
    "        authors = ref_authors.get(\"author\", [])\n",
    "        if not isinstance(authors, list):\n",
    "            authors = [authors] if authors else []\n",
    "        reference_info[\"ref_authors\"] = [author.get(\"ce:indexed-name\", \"\") for author in authors]\n",
    "        reference_info[\"ref_authors_count\"] = len(reference_info[\"ref_authors\"])\n",
    "\n",
    "        collaborations = ref_authors.get(\"collaboration\", [])\n",
    "        if not isinstance(collaborations, list):\n",
    "            collaborations = [collaborations] if collaborations else []\n",
    "        reference_info[\"ref_collab\"] = [{\"collaboration_name\": collab.get(\"ce:text\", \"\")} for collab in collaborations]\n",
    "\n",
    "        bibliography_output[\"references\"].append(reference_info)\n",
    "\n",
    "    return bibliography_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa68600-aa41-416d-8dc1-046672b46cd3",
   "metadata": {},
   "source": [
    "# Function for get the required Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "77f7b6ab-3fa2-4539-8206-9d85b2c60a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_feature(data, file_name):\n",
    "    output_data = {\n",
    "        \"id\": str(file_name),\n",
    "        \"source\": 1,\n",
    "        \"coAuthorship\": 0,\n",
    "        \"citationCount\": 0,\n",
    "        \"refCount\": 0,\n",
    "        \"Class\": []\n",
    "    }\n",
    "\n",
    "    bibrecord_data = data['item']['bibrecord']\n",
    "    \n",
    "    # find num authorship\n",
    "    head_data = process_head_data(bibrecord_data)\n",
    "    output_data['coAuthorship'] = num_author_group(head_data['author_groups'])\n",
    "\n",
    "    # find citation count\n",
    "    item_info = bibrecord_data['item-info']\n",
    "    if \"ce:doi\" not in item_info['itemidlist']:\n",
    "        output_data['citationCount'] = None\n",
    "    else :\n",
    "        doi = item_info['itemidlist']['ce:doi']\n",
    "        output_data['citationCount'] = get_citation_count(doi)\n",
    "\n",
    "    # find the references count\n",
    "    tail_data = process_tail_data(bibrecord_data)\n",
    "    output_data['refCount'] = tail_data['refcount']\n",
    "\n",
    "    # get the class\n",
    "    enhancement_data = head_data['enhancement']\n",
    "    for item in enhancement_data:\n",
    "        if item['type'] == 'SUBJABBR':\n",
    "            for subject in item['classifications']:\n",
    "                output_data['Class'].append(subject)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9975b51-74ed-434d-afbd-eeb4b943ce8b",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2e279-7387-469a-9d12-b3ae849dfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import time\n",
    "import json\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer=lambda x: json.dumps(x).encode('utf-8'),\n",
    "    request_timeout_ms=60000,  # Increase timeout to 60 seconds\n",
    "    retry_backoff_ms=500,  # Increase backoff time between retries\n",
    ")\n",
    "\n",
    "def process_directory(base_path):\n",
    "    for year in range(2018, 2019):  # Assuming years 2018 to 2023\n",
    "        year_path = os.path.join(base_path, str(year), f'{year}')\n",
    "        if os.path.isdir(year_path):\n",
    "            for file_name in os.listdir(year_path):\n",
    "                file_path = os.path.join(year_path, file_name)\n",
    "                # Detect file encoding\n",
    "                with open(file_path, 'rb') as f:  # open in binary mode\n",
    "                    raw_data = f.read()\n",
    "                    result = chardet.detect(raw_data)\n",
    "                    encoding = result['encoding']\n",
    "\n",
    "                # Read the file with detected encoding\n",
    "                with open(file_path, 'r', encoding=encoding) as file:\n",
    "                    json_data = json.load(file)\n",
    "                    abstracts_info = json_data.get(\"abstracts-retrieval-response\", {})\n",
    "                    data = get_all_feature(abstracts_info, file_name)\n",
    "                    try:\n",
    "                        producer.send('test-topic', value=data).get(timeout=30)  # Wait up to 30 seconds\n",
    "                        print(f\"Sent: {data}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to send message: {str(e)}\", file_name)\n",
    "                    time.sleep(1)\n",
    "\n",
    "\n",
    "process_directory('./')\n",
    "\n",
    "producer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
