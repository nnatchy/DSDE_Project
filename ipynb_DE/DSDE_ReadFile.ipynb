{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade avro==1.10.0 kafka-python\n",
        "%pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swJBqA_MSQvj",
        "outputId": "17a6cc7f-83ad-4507-8631-470ac8381a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avro==1.10.0\n",
            "  Downloading avro-1.10.0.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: avro\n",
            "  Building wheel for avro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro: filename=avro-1.10.0-py3-none-any.whl size=96719 sha256=6b86205a408fb9f4717c40171c9add7bb894935a96c83ee3503e12cadbc22d4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/45/02/59d22f799de5f011ddd515bf6e2e3b8c929ef56129008fe2b8\n",
            "Successfully built avro\n",
            "Installing collected packages: kafka-python, avro\n",
            "Successfully installed avro-1.10.0 kafka-python-2.0.2\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.20.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.20.0 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from avro import schema\n",
        "from avro.io import DatumWriter, BinaryEncoder\n",
        "from kafka import KafkaConsumer, KafkaProducer\n",
        "\n",
        "import re\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.firefox.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pprint  # Import pprint for pretty printing"
      ],
      "metadata": {
        "id": "fp5SJXvySTDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=yellow>1.Read file\n",
        "* As we are trying to make the given data more readable, this is the first step for doing a data formatting\n",
        "* using the ```json``` library to handle the structure of the data"
      ],
      "metadata": {
        "id": "hyFDT_R4QZjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Read file of specified year (not finished)\n",
        "\n",
        "- you need to upload the zip of the year you want and it will unzip and store all of the json in the folder"
      ],
      "metadata": {
        "id": "o55TysKmImQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"2018\""
      ],
      "metadata": {
        "id": "PdGOxOCYzv4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec058f4c-68cf-4b6c-c8a1-de8759e7e785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '2018': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base path where the zip files are stored and where directories are created\n",
        "base_path = './'\n",
        "\n",
        "# Create a directory for each year and unzip the corresponding file\n",
        "years = range(2018, 2024)  # Years 2018 to 2023\n",
        "for year in years:\n",
        "    # Construct the path for the year directory\n",
        "    year_dir = os.path.join(base_path, str(year))\n",
        "    # Create the directory if it does not exist\n",
        "    os.makedirs(year_dir, exist_ok=True)\n",
        "\n",
        "    # Construct the zip file path for the current year\n",
        "    zip_path = os.path.join(base_path, f'{year}.zip')\n",
        "\n",
        "    # Check if the zip file exists\n",
        "    if os.path.exists(zip_path):\n",
        "        # Open the zip file\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:  # corrected to use `zip_path`\n",
        "            # Extract all the contents into the directory of the current year\n",
        "            zip_ref.extractall(year_dir)\n",
        "            print(f\"All files from {zip_path} have been extracted to {year_dir}\")\n",
        "    else:\n",
        "        print(f\"No zip file found for {year} at {zip_path}\")\n",
        "\n",
        "print(\"All applicable files have been extracted and sorted by year.\")\n"
      ],
      "metadata": {
        "id": "W8tP9OSvHkKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1040f1a-fd5d-4284-b63a-f3a55dd1392b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files from ./2018.zip have been extracted to ./2018\n",
            "All files from ./2019.zip have been extracted to ./2019\n",
            "All files from ./2020.zip have been extracted to ./2020\n",
            "All files from ./2021.zip have been extracted to ./2021\n",
            "All files from ./2022.zip have been extracted to ./2022\n",
            "All files from ./2023.zip have been extracted to ./2023\n",
            "All applicable files have been extracted and sorted by year.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bnZg21IOGaV"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file\n",
        "with open(\"./2018/2018 copy/201800051\", 'r') as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "# Display a part of the JSON data to understand its structure\n",
        "# Show only a limited part to avoid too much output if the file is large\n",
        "json_data_part = json.dumps(json_data, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_dict(d, indent=0):\n",
        "    \"\"\" Recursively prints nested dictionaries.\"\"\"\n",
        "    for key, value in d.items():\n",
        "        print('    ' * indent + str(key), end='')\n",
        "        if isinstance(value, dict):\n",
        "            print()  # Print the key and start a new line for nested dictionary\n",
        "            print_dict(value, indent+1)  # Recursive call to print nested dictionary\n",
        "        else:\n",
        "            print(': ' + str(value))  # Print key-value pair"
      ],
      "metadata": {
        "id": "j9uFEeOUQYhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this to see a big pile of data that is un-formatted\n",
        "#print_dict(json_data)"
      ],
      "metadata": {
        "id": "E9Vbdqy9Qls3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this function to print the json with the indent=4\n",
        "def jprint(data):\n",
        "  print(json.dumps(data,indent=4))"
      ],
      "metadata": {
        "id": "HDwxNKYgmgMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='yellow'> 2.Abstract Info\n",
        "* this will be the outer-most scope of our data\n",
        "* we will see that we have 8 inner scope for the this scope\n",
        "  * in which, we will dives into the important ones\n",
        "  * includes ```item```, ```coredata```, ```idxterms```, ```authkeywords``` and ```subject-areas```"
      ],
      "metadata": {
        "id": "YWiEWn2Al9Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstracts_info = json_data[\"abstracts-retrieval-response\"]\n",
        "for topic in abstracts_info:\n",
        "  print(topic)"
      ],
      "metadata": {
        "id": "wel638zZmH77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275fe1fc-8213-46e9-ac36-74c11e6f7fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item\n",
            "affiliation\n",
            "coredata\n",
            "idxterms\n",
            "language\n",
            "authkeywords\n",
            "subject-areas\n",
            "authors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing different parts of the abstract information\n",
        "abstracts_info_item = abstracts_info[\"item\"]\n",
        "abstract_info_coredata = abstracts_info[\"coredata\"]\n",
        "abstract_info_idxterms = abstracts_info[\"idxterms\"]\n",
        "abstract_info_authkeywords = abstracts_info.get(\"authkeywords\", [])  # Default to empty list if null\n",
        "abstract_info_subject = abstracts_info.get(\"subject-areas\", [])  # Default to empty list if null"
      ],
      "metadata": {
        "id": "6oGqIwlHQTM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize it accordingly"
      ],
      "metadata": {
        "id": "yVWUkmEcyx8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_abstract_data(abstract_info):\n",
        "    try:\n",
        "        affiliation_info = abstract_info.get(\"affiliation\", [])\n",
        "        # Ensure affiliation_info is always a list\n",
        "        if isinstance(affiliation_info, dict):\n",
        "            affiliation_info = [affiliation_info]  # Normalize single dict to list\n",
        "        elif not isinstance(affiliation_info, list):\n",
        "            raise ValueError(\"affiliation data is neither a dictionary nor a list\")\n",
        "\n",
        "        affiliation_structure = {}\n",
        "        num_affi = num_city = num_country = 0\n",
        "        uni = []\n",
        "\n",
        "        for affiliation in affiliation_info:\n",
        "            # Ensure each affiliation is a dictionary\n",
        "            if not isinstance(affiliation, dict):\n",
        "                continue  # Skip if the affiliation is not a dictionary\n",
        "\n",
        "            country = affiliation.get(\"affiliation-country\", \"Unknown Country\")\n",
        "            city = affiliation.get(\"affiliation-city\", \"Unknown City\")\n",
        "            affi_name = affiliation.get(\"affilname\", \"\")\n",
        "\n",
        "            if \"University\" in affi_name:\n",
        "                uni.append(affi_name)\n",
        "\n",
        "            affil_dict = {\n",
        "                \"affilname\": affi_name,\n",
        "                \"href\": affiliation.get(\"@href\", \"\")\n",
        "            }\n",
        "\n",
        "            if country not in affiliation_structure:\n",
        "                affiliation_structure[country] = {}\n",
        "                num_country += 1\n",
        "\n",
        "            if city not in affiliation_structure[country]:\n",
        "                affiliation_structure[country][city] = []\n",
        "                num_city += 1\n",
        "\n",
        "            affiliation_structure[country][city].append(affil_dict)\n",
        "            num_affi += 1\n",
        "\n",
        "        affiliation_structure[\"Statistics\"] = {\n",
        "            \"num_affiliations\": num_affi,\n",
        "            \"num_university\": len(set(uni)),\n",
        "            \"num_country\": num_country,\n",
        "            \"num_city\": num_city\n",
        "        }\n",
        "        return affiliation_structure\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        # Depending on your use case, you might want to return an empty dict, raise the exception, or handle it differently\n",
        "        return {}\n"
      ],
      "metadata": {
        "id": "VMIFvPs6GTMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Old split"
      ],
      "metadata": {
        "id": "c_tVhHSoH8qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the important ones\n",
        "abstracts_info_item = abstracts_info[\"item\"]\n",
        "abstract_info_coredata = abstracts_info[\"coredata\"]\n",
        "abstract_info_idxterms = abstracts_info[\"idxterms\"]\n",
        "abstract_info_authkeywords = abstracts_info[\"authkeywords\"]  # Can be null\n",
        "abstract_info_subject = abstracts_info[\"subject-areas\"]\n"
      ],
      "metadata": {
        "id": "l5iuvHiRy6T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look into the unimportant ones as well\n",
        "affiliation_info = abstracts_info[\"affiliation\"]\n",
        "language = abstracts_info[\"language\"]"
      ],
      "metadata": {
        "id": "AFPluL2gz_2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming affiliation_info can be a dict or a list of dicts\n",
        "\n",
        "# Normalize affiliation_info to always be a list\n",
        "if isinstance(affiliation_info, dict):\n",
        "    affiliation_info = [affiliation_info]  # Make it a list if it's just a single dict\n",
        "\n",
        "# Initialize a dictionary to organize the data\n",
        "affiliation_structure = {}\n",
        "num_affi = 0\n",
        "num_city = 0\n",
        "num_country = 0\n",
        "uni = []\n",
        "\n",
        "# Iterate through each affiliation entry\n",
        "for affiliation in affiliation_info:\n",
        "    country = affiliation.get(\"affiliation-country\", \"Unknown Country\")\n",
        "    city = affiliation.get(\"affiliation-city\", \"Unknown City\")\n",
        "    # Create a dictionary for each affiliation containing the name and href\n",
        "\n",
        "    affi_name = affiliation.get(\"affilname\", \"\")\n",
        "    if \"University\" in affi_name:\n",
        "      uni.append(affi_name)\n",
        "\n",
        "    affil_dict = {\n",
        "        \"affilname\": affi_name,\n",
        "        \"href\": affiliation.get(\"@href\", \"\")\n",
        "    }\n",
        "\n",
        "    # Check if the country key exists, if not, initialize it\n",
        "    if country not in affiliation_structure:\n",
        "        affiliation_structure[country] = {}\n",
        "        num_country += 1\n",
        "\n",
        "    # Check if the city key exists in the country's dict, if not, initialize it\n",
        "    if city not in affiliation_structure[country]:\n",
        "        affiliation_structure[country][city] = []\n",
        "        num_city += 1\n",
        "\n",
        "    # Append the dictionary to the city list\n",
        "    affiliation_structure[country][city].append(affil_dict)\n",
        "    num_affi += 1\n",
        "\n",
        "\n",
        "affiliation_structure[\"Statistics\"] = {\n",
        "    \"num_affiliations\": num_affi,\n",
        "    \"num_university\": len(set(uni)),\n",
        "    \"num_country\": num_country,\n",
        "    \"num_city\": num_city\n",
        "}\n",
        "# Print the organized structure\n",
        "jprint(affiliation_structure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7-fg8H59nC",
        "outputId": "043c16fe-7c82-4426-b839-73dc484dadbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Thailand\": {\n",
            "        \"Bangkok\": [\n",
            "            {\n",
            "                \"affilname\": \"Chulalongkorn University\",\n",
            "                \"href\": \"https://api.elsevier.com/content/affiliation/affiliation_id/60028190\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    \"Statistics\": {\n",
            "        \"num_affiliations\": 1,\n",
            "        \"num_university\": 1,\n",
            "        \"num_country\": 1,\n",
            "        \"num_city\": 1\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLIRc1ib0Yl7",
        "outputId": "b271f9bf-b663-4372-ef7d-a271ba32ba4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@xml:lang': 'eng'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"yellow\">3.Item\n",
        "* this might be where the most data is stored\n",
        "* And after carefully examining the data, the Item data is stored like this diagram\n",
        "```\n",
        "item -> \"ait:process-info\"\n",
        "       -> \"xocs:meta\"\n",
        "       -> \"bibrecord\" -> \"head\"\n",
        "                      -> \"item-info\"\n",
        "                      -> \"tail\"\n",
        "```"
      ],
      "metadata": {
        "id": "pKtG9aFD0dDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first two as well, uncomment to see each one\n",
        "jprint(abstracts_info_item['ait:process-info'])\n",
        "\n",
        "# this one might or might not provided in the data\n",
        "# jprint(abstracts_info_item['xocs:meta'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quwFpiZg3dA3",
        "outputId": "15e6750a-101a-4fd2-ef80-fc6c0292e46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"ait:status\": {\n",
            "        \"@state\": \"update\",\n",
            "        \"@type\": \"core\",\n",
            "        \"@stage\": \"S300\"\n",
            "    },\n",
            "    \"ait:date-delivered\": {\n",
            "        \"@day\": \"10\",\n",
            "        \"@year\": \"2020\",\n",
            "        \"@timestamp\": \"2020-02-10T17:30:52.000052-05:00\",\n",
            "        \"@month\": \"02\"\n",
            "    },\n",
            "    \"ait:date-sort\": {\n",
            "        \"@day\": \"30\",\n",
            "        \"@year\": \"2018\",\n",
            "        \"@month\": \"12\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Look at the \"bibrecord\"\n",
        "which will be most of the data in the \"item\" field"
      ],
      "metadata": {
        "id": "BE-4uyjvmBMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bibrecord_data = abstracts_info_item[\"bibrecord\"]"
      ],
      "metadata": {
        "id": "vE0OokxpVXNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1. Starting with head\n",
        "extract the neccessary field\n",
        "```\n",
        "-> \"bibrecord\" -> \"head\"   // looking at this one\n",
        "               -> \"item-info\"\n",
        "               -> \"tail\"\n",
        "```\n",
        "\n",
        "```\n",
        "-> \"head\" -> \"author-group\"  \n",
        "          -> \"correspondence\"   // might not have\n",
        "          -> \"citation-title\"\n",
        "          -> \"abstracts\"\n",
        "          -> \"citation-info\"\n",
        "          -> \"source\"\n",
        "          -> \"enhancement\n",
        "          -> \"grantlist\"       // not important\n",
        "```"
      ],
      "metadata": {
        "id": "eabtOWi4U8WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head_output_data = bibrecord_data['head']"
      ],
      "metadata": {
        "id": "0u47uO-yAzUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in head_output_data:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC6OjSBuRWIo",
        "outputId": "9efcaa58-1e0c-4915-b64d-7bd5c61c4485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author-group\n",
            "citation-title\n",
            "abstracts\n",
            "citation-info\n",
            "source\n",
            "enhancement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_bibliographic_head_data(bibrecord_data):\n",
        "    head = bibrecord_data.get(\"head\", {})\n",
        "    head_output_data = {\n",
        "        \"author_groups\": [],\n",
        "        \"correspondence\": [],\n",
        "        \"enhancement\": [],\n",
        "        \"citation_title\": head.get(\"citation-title\", \"\"),\n",
        "        \"abstracts\": head.get(\"abstracts\", \"\")\n",
        "    }\n",
        "\n",
        "    # Process author groups\n",
        "    author_groups = head.get(\"author-group\", [])\n",
        "    if isinstance(author_groups, dict):\n",
        "        author_groups = [author_groups]\n",
        "\n",
        "    for author in author_groups:\n",
        "        affi = author.get(\"affiliation\", {})\n",
        "        org = affi.get(\"organization\", [])\n",
        "        organization_names = [org.get(\"$\", \"\")] if isinstance(org, dict) else [o.get(\"$\", \"\") for o in org if isinstance(o, dict)]\n",
        "        authors_list = author.get(\"author\", [])\n",
        "        authors_list = [authors_list] if isinstance(authors_list, dict) else authors_list\n",
        "\n",
        "        for person in authors_list:\n",
        "            author_info = {\n",
        "                \"indexed-name\": person.get(\"preferred-name\", {}).get(\"ce:indexed-name\", \"\"),\n",
        "                \"seq\": person.get(\"@seq\", \"\"),\n",
        "                \"auid\": person.get(\"@auid\", \"\"),\n",
        "                \"affiliation\": {\n",
        "                    \"affiliation_id\": affi.get(\"@afid\", \"\"),\n",
        "                    \"dpt_id\": affi.get(\"@dptid\", \"\"),\n",
        "                    \"country\": affi.get(\"country\", \"\"),\n",
        "                    \"organization\": organization_names\n",
        "                }\n",
        "            }\n",
        "            head_output_data[\"author_groups\"].append(author_info)\n",
        "\n",
        "    # Process correspondence\n",
        "    correspondence_data = head.get(\"correspondence\", [])\n",
        "    if not isinstance(correspondence_data, list):\n",
        "        correspondence_data = [correspondence_data] if correspondence_data else []\n",
        "\n",
        "    for item in correspondence_data:\n",
        "        if isinstance(item, dict):\n",
        "            person_info = item.get(\"person\", {})\n",
        "            correspondence_info = {\n",
        "                \"affiliation\": {\n",
        "                    \"organization\": [aff.get(\"$\", \"\") for aff in item.get(\"affiliation\", {}).get(\"organization\", []) if isinstance(aff, dict)]\n",
        "                },\n",
        "                \"person\": {\n",
        "                    \"given_name\": person_info.get(\"ce:given-name\", \"\"),\n",
        "                    \"initials\": person_info.get(\"ce:initials\", \"\"),\n",
        "                    \"surname\": person_info.get(\"ce:surname\", \"\"),\n",
        "                    \"indexed_name\": person_info.get(\"ce:indexed-name\", \"\")\n",
        "                }\n",
        "            }\n",
        "            head_output_data[\"correspondence\"].append(correspondence_info)\n",
        "\n",
        "    # Enhancements\n",
        "    enhancements = head.get(\"enhancement\", {})\n",
        "    classifications = enhancements.get(\"classificationgroup\", {}).get(\"classifications\", [])\n",
        "    if isinstance(classifications, dict):\n",
        "        classifications = [classifications]\n",
        "\n",
        "    for classification in classifications:\n",
        "        class_content = classification.get(\"classification\", [])\n",
        "        class_content = [class_content] if isinstance(class_content, dict) else class_content\n",
        "        class_info = {\n",
        "            \"type\": classification.get(\"@type\"),\n",
        "            \"classifications\": [item.get(\"$\", item) for item in class_content if isinstance(item, dict)]\n",
        "        }\n",
        "        head_output_data[\"enhancement\"].append(class_info)\n",
        "\n",
        "    # Source information\n",
        "    source_info = head.get(\"source\", {})\n",
        "    website_info = source_info.get(\"website\", {})\n",
        "    website_address = \"\"\n",
        "    if isinstance(website_info, list):\n",
        "        # Assuming the first item in the list contains the 'ce:e-address' if the list is not structured as expected\n",
        "        website_address = website_info[0].get(\"ce:e-address\", {}).get(\"$\", \"\") if isinstance(website_info[0], dict) else \"\"\n",
        "    elif isinstance(website_info, dict):\n",
        "        website_address = website_info.get(\"ce:e-address\", {}).get(\"$\", \"\")\n",
        "\n",
        "    head_output_data[\"source\"] = {\n",
        "        \"website_address\": website_address,\n",
        "        \"publication_date\": source_info.get(\"publicationdate\", \"\"),\n",
        "        \"publisher_name\": source_info.get(\"publisher\", {}).get(\"publishername\", \"\")\n",
        "    }\n",
        "\n",
        "    return head_output_data\n"
      ],
      "metadata": {
        "id": "YgrMBB6EJmfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Old Data Processing"
      ],
      "metadata": {
        "id": "KPofwlbTXhRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume bibrecord_data is loaded as a dictionary from your JSON data\n",
        "# Normalize 'author-group' to always be a list\n",
        "author_groups = bibrecord_data[\"head\"][\"author-group\"]\n",
        "if isinstance(author_groups, dict):\n",
        "    author_groups = [author_groups]  # Make it a list if it's just a single dict\n",
        "\n",
        "# Initialize a storage structure for processed data\n",
        "head_output_data = {\"author_groups\": []}\n",
        "\n",
        "# Iterate over each author group in the data\n",
        "for author in author_groups:\n",
        "    # Extract affiliation details if available\n",
        "    affi = author.get(\"affiliation\", {})\n",
        "\n",
        "    # Handling the 'organization' field which can be either a dictionary or a list\n",
        "    org = affi.get(\"organization\", [])\n",
        "    if isinstance(org, dict):  # If 'organization' is a dictionary, make it a list\n",
        "        organization_names = [org[\"$\"]]\n",
        "    elif isinstance(org, list):  # If 'organization' is already a list, process normally\n",
        "        organization_names = [o[\"$\"] for o in org]\n",
        "    else:\n",
        "        organization_names = []  # Safe fallback if 'organization' is neither dict nor list\n",
        "\n",
        "    affi_info = {\n",
        "        \"affiliation_id\": affi.get(\"@afid\", \"\"),\n",
        "        \"dpt_id\": affi.get(\"@dptid\", \"\"),\n",
        "        \"country\": affi.get(\"country\", \"\"),\n",
        "        \"organization\": organization_names  # Use the processed list\n",
        "    }\n",
        "\n",
        "    # Extract individual author details including their affiliation\n",
        "    authors = author.get(\"author\", [])\n",
        "    if isinstance(authors, dict):  # Ensure 'authors' is always a list\n",
        "        authors = [authors]\n",
        "\n",
        "    # Process each author in the list\n",
        "    for person in authors:\n",
        "        author_info = {\n",
        "            \"indexed-name\": person.get(\"preferred-name\", {}).get(\"ce:indexed-name\", \"\"),\n",
        "            \"seq\": person.get(\"@seq\", \"\"),\n",
        "            \"auid\": person.get(\"@auid\", \"\"),\n",
        "            \"affiliation\": affi_info  # Include affiliation info\n",
        "        }\n",
        "        head_output_data[\"author_groups\"].append(author_info)"
      ],
      "metadata": {
        "id": "Vt3UVr9NDchQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the correspondence data to always be a list\n",
        "if \"correspondence\" in bibrecord_data[\"head\"]:\n",
        "    head_output_data[\"correspondence\"] = []\n",
        "    correspondence_data = bibrecord_data[\"head\"][\"correspondence\"]\n",
        "    # Check if correspondence_data is not a list, then make it a list\n",
        "    if not isinstance(correspondence_data, list):\n",
        "        correspondence_data = [correspondence_data]\n",
        "\n",
        "    for index, item in enumerate(correspondence_data):\n",
        "        # print(f\"Inspecting item {index} in correspondence:\", item)\n",
        "\n",
        "        # Initialize default values for correspondence info\n",
        "        affiliation_info = {\"affiliation_instance_id\": \"\", \"organization\": []}\n",
        "        person_info = {\"author_instance_id\": \"\"}\n",
        "\n",
        "        # Ensure 'item' is a dictionary\n",
        "        if isinstance(item, dict):\n",
        "            # Extract affiliation details if available and correctly structured\n",
        "            if 'affiliation' in item and isinstance(item['affiliation'], dict):\n",
        "                affiliation = item['affiliation']\n",
        "                # print(\"AFFILIATION\", affiliation)\n",
        "\n",
        "                # Normalize 'organization' to always be a list\n",
        "                organization_data = affiliation.get(\"organization\", [])\n",
        "                if isinstance(organization_data, dict):  # If 'organization' is a single dict, make it a list\n",
        "                    organization_data = [organization_data]\n",
        "\n",
        "                # Extract 'organization' details safely\n",
        "                organizations = [org[\"$\"] for org in organization_data if \"$\" in org]\n",
        "\n",
        "                affiliation_info = {\n",
        "                    \"organization\": organizations\n",
        "                }\n",
        "\n",
        "            # Extract person details if available and correctly structured\n",
        "            if 'person' in item and isinstance(item['person'], dict):\n",
        "                person = item['person']\n",
        "                person_info = {\n",
        "                    \"given_name\": person.get(\"ce:given-name\", \"\"),\n",
        "                    \"initials\": person.get(\"ce:initials\", \"\"),\n",
        "                    \"surname\": person.get(\"ce:surname\", \"\"),\n",
        "                    \"indexed_name\": person.get(\"ce:indexed-name\", \"\")\n",
        "                }\n",
        "\n",
        "            # Compile the correspondence information\n",
        "            correspondence_info = {\n",
        "                \"affiliation\": affiliation_info,\n",
        "                \"person\": person_info\n",
        "            }\n",
        "            head_output_data[\"correspondence\"].append(correspondence_info)\n",
        "        else:\n",
        "            print(f\"Error: Item {index} in correspondence is not a dictionary, but {type(item)}\")\n",
        "else:\n",
        "    print(\"Error: 'correspondence' not found or is not a list\")"
      ],
      "metadata": {
        "id": "GodII3jTDiFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c22c09-a73a-49f6-8813-e05d22188679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'correspondence' not found or is not a list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract source information\n",
        "head_output_data[\"source\"] = {\n",
        "    \"website_address\": bibrecord_data[\"head\"][\"source\"][\"website\"][\"ce:e-address\"][\"$\"],\n",
        "    \"publication_date\": bibrecord_data[\"head\"][\"source\"][\"publicationdate\"],\n",
        "    \"publisher_name\": bibrecord_data[\"head\"][\"source\"][\"publisher\"][\"publishername\"]\n",
        "}"
      ],
      "metadata": {
        "id": "HTvMAVrbDksp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_output_data[\"enhancement\"] = []\n",
        "\n",
        "# Check if 'enhancement' and 'classificationgroup' keys are present and properly structured\n",
        "if \"enhancement\" in bibrecord_data[\"head\"] and \"classificationgroup\" in bibrecord_data[\"head\"][\"enhancement\"]:\n",
        "    classifications = bibrecord_data[\"head\"][\"enhancement\"][\"classificationgroup\"].get(\"classifications\", [])\n",
        "\n",
        "    # Normalize classifications to always be a list\n",
        "    if isinstance(classifications, dict):\n",
        "        classifications = [classifications]  # Make a single dict a list for uniform processing\n",
        "\n",
        "    # Extract enhancement information for specific classification type\n",
        "    for classification in classifications:\n",
        "        if classification[\"@type\"] == \"SUBJABBR\":  # Check for the specific type\n",
        "            # Handle the classification detail, which could be direct string or list or dict\n",
        "            if isinstance(classification.get(\"classification\"), (list, dict)):\n",
        "                # If it's a list, extract all values\n",
        "                if isinstance(classification[\"classification\"], list):\n",
        "                    all_classifications = [item.get(\"$\", item) if isinstance(item, dict) else item for item in classification[\"classification\"]]\n",
        "                else:  # If it's a dictionary\n",
        "                    all_classifications = [classification[\"classification\"].get(\"$\", classification[\"classification\"])]\n",
        "            else:  # It's a string directly\n",
        "                all_classifications = [classification[\"classification\"]]\n",
        "\n",
        "            class_info = {\n",
        "                \"type\": classification[\"@type\"],\n",
        "                \"classifications\": all_classifications\n",
        "            }\n",
        "            head_output_data[\"enhancement\"].append(class_info)"
      ],
      "metadata": {
        "id": "P4Tv01cjDnvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract citation title and abstracts\n",
        "head_output_data[\"citation_title\"] = bibrecord_data[\"head\"][\"citation-title\"]\n",
        "head_output_data[\"abstracts\"] = bibrecord_data[\"head\"][\"abstracts\"]"
      ],
      "metadata": {
        "id": "PFeHgqs-DZyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in head_output_data:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kzo3l1KpPrd",
        "outputId": "b8fd7686-4e4c-47ba-97e7-c23283fb95b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author_groups\n",
            "source\n",
            "enhancement\n",
            "citation_title\n",
            "abstracts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Author Group"
      ],
      "metadata": {
        "id": "ErUETCD9elJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to find how many author are in this paper\n",
        "def num_author_group(head_data):\n",
        "  num = 0\n",
        "  for author in head_data:\n",
        "    if int(author['seq']) > num:\n",
        "      num = int(author['seq'])\n",
        "\n",
        "  return num"
      ],
      "metadata": {
        "id": "TVGFvtgra9lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_group = head_output_data[\"author_groups\"]\n",
        "jprint(author_group)\n",
        "print(\"Number of Author in this paper is: \" + str(num_author_group(author_group)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGY7V20Iiwho",
        "outputId": "0f210caf-d669-4721-c180-e548f44d3132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"indexed-name\": \"Karnkawinpong T.\",\n",
            "        \"seq\": \"1\",\n",
            "        \"auid\": \"57207728099\",\n",
            "        \"affiliation\": {\n",
            "            \"affiliation_id\": \"60028190\",\n",
            "            \"dpt_id\": \"113891981\",\n",
            "            \"country\": \"Thailand\",\n",
            "            \"organization\": [\n",
            "                \"Department of Computer Engineering\",\n",
            "                \"Chulalongkorn University\"\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"indexed-name\": \"Limpiyakorn Y.\",\n",
            "        \"seq\": \"2\",\n",
            "        \"auid\": \"56032668700\",\n",
            "        \"affiliation\": {\n",
            "            \"affiliation_id\": \"60028190\",\n",
            "            \"dpt_id\": \"113891981\",\n",
            "            \"country\": \"Thailand\",\n",
            "            \"organization\": [\n",
            "                \"Department of Computer Engineering\",\n",
            "                \"Chulalongkorn University\"\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "]\n",
            "Number of Author in this paper is: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Enhancement"
      ],
      "metadata": {
        "id": "lNoQnUFlX2yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = head_output_data['enhancement']\n",
        "jprint(classifications)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz20IFMwXl7V",
        "outputId": "e2bf49c2-f190-48b0-c585-8c017d0dfb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"type\": \"SUBJABBR\",\n",
            "        \"classifications\": [\n",
            "            \"BIOC\"\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correspondence"
      ],
      "metadata": {
        "id": "zyOkIbOcKrCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'correspondence' in head_output_data:\n",
        "  jprint(head_output_data['correspondence'])"
      ],
      "metadata": {
        "id": "DofEEscuKan9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f106ba-a397-4592-b6e4-26ec8b12895a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"affiliation\": {\n",
            "            \"organization\": [\n",
            "                \"Division of Medical Genetics and Metabolism\",\n",
            "                \"Department of Pediatrics\",\n",
            "                \"Faculty of Medicine\",\n",
            "                \"Chulalongkorn University\"\n",
            "            ]\n",
            "        },\n",
            "        \"person\": {\n",
            "            \"given_name\": \"Kanya\",\n",
            "            \"initials\": \"K.\",\n",
            "            \"surname\": \"Suphapeetiporn\",\n",
            "            \"indexed_name\": \"Suphapeetiporn K.\"\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2. Look at the \"item-info\"\n",
        "```\n",
        "-> \"bibrecord\" -> \"head\"   \n",
        "               -> \"item-info\" // looking at this one\n",
        "               -> \"tail\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "T5Y0fIdLgg7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_bibliography_item_info_data(bibrecord_data):\n",
        "    item_info_output = {\n",
        "        \"external_source\": \"\",\n",
        "        \"history\": {}\n",
        "    }\n",
        "\n",
        "    item_info = bibrecord_data.get(\"item-info\", {})\n",
        "    if not item_info:  # Check if item_info is empty or None\n",
        "        return item_info_output\n",
        "\n",
        "    item_info_output[\"external_source\"] = item_info.get(\"external-source\", \"\")\n",
        "\n",
        "    history = item_info.get(\"history\", {})\n",
        "    date_created = history.get(\"date-created\", {})\n",
        "    item_info_output[\"history\"] = {\n",
        "        \"day\": date_created.get(\"@day\", \"\"),\n",
        "        \"timestamp\": date_created.get(\"@timestamp\", \"\"),\n",
        "        \"year\": date_created.get(\"@year\", \"\"),\n",
        "        \"month\": date_created.get(\"@month\", \"\")\n",
        "    }\n",
        "\n",
        "    return item_info_output\n"
      ],
      "metadata": {
        "id": "XCfmLItqLVc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### old fn"
      ],
      "metadata": {
        "id": "qG9zieekLTF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the output dictionary for item-info\n",
        "item_info_output = {\n",
        "    \"external_source\": \"\",\n",
        "    \"history\": {}\n",
        "}\n",
        "\n",
        "# Access the 'item-info' from the data\n",
        "if \"item-info\" in bibrecord_data:\n",
        "    item_info = bibrecord_data[\"item-info\"]\n",
        "\n",
        "    # Extract 'external-source' if available\n",
        "    item_info_output[\"external_source\"] = item_info.get(\"external-source\", \"\")\n",
        "\n",
        "    # Extract 'history' details if available\n",
        "    if \"history\" in item_info:\n",
        "        history = item_info[\"history\"]\n",
        "        if \"date-created\" in history:\n",
        "            date_created = history[\"date-created\"]\n",
        "            item_info_output[\"history\"] = {\n",
        "                \"day\": date_created.get(\"@day\", \"\"),\n",
        "                \"timestamp\": date_created.get(\"@timestamp\", \"\"),\n",
        "                \"year\": date_created.get(\"@year\", \"\"),\n",
        "                \"month\": date_created.get(\"@month\", \"\")\n",
        "            }\n",
        "\n",
        "# Print the extracted item-info data\n",
        "jprint(item_info_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vecC7DZh4qI",
        "outputId": "2d3c682d-277b-4116-8012-8f50c5681fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"external_source\": \"MEDLINE\",\n",
            "    \"history\": {\n",
            "        \"day\": \"25\",\n",
            "        \"timestamp\": \"BST 16:36:48\",\n",
            "        \"year\": \"2018\",\n",
            "        \"month\": \"10\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 Look at the \"tail\"\n",
        "```\n",
        "-> \"bibrecord\" -> \"head\"   \n",
        "               -> \"item-info\"\n",
        "               -> \"tail\"  // looking at this one\n",
        "```"
      ],
      "metadata": {
        "id": "Ld37-J5wh655"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_bibliography_tail_data(bibrecord_data):\n",
        "    # Ensure 'tail' is a dictionary before proceeding\n",
        "    tail_info = bibrecord_data.get(\"tail\", {})\n",
        "\n",
        "    bibliography_output = {\n",
        "        \"refcount\": \"\",\n",
        "        \"references\": []\n",
        "    }\n",
        "\n",
        "    if not tail_info:  # Check if tail_info is empty or None\n",
        "        return bibliography_output\n",
        "\n",
        "    bibliography = tail_info.get(\"bibliography\", {})\n",
        "    bibliography_output[\"refcount\"] = bibliography.get(\"@refcount\", \"0\")\n",
        "\n",
        "    # Handle references\n",
        "    references = bibliography.get(\"reference\", [])\n",
        "    if not isinstance(references, list):\n",
        "        references = [references] if references else []\n",
        "\n",
        "    for ref in references:\n",
        "        reference_info = {\n",
        "            \"id\": ref.get(\"@id\", \"\"),\n",
        "            \"ref_fulltext\": ref.get(\"ref-fulltext\", \"\"),\n",
        "            \"ref_text\": ref.get(\"ce:source-text\", \"\"),\n",
        "            \"ref_info\": {},\n",
        "            \"ref_authors\": [],\n",
        "            \"ref_authors_count\": \"\",\n",
        "            \"ref_collab\": []\n",
        "        }\n",
        "\n",
        "        ref_info = ref.get(\"ref-info\", {})\n",
        "        reference_info[\"ref_info\"] = {\n",
        "            \"ref_publicationyear\": ref_info.get(\"ref-publicationyear\", {}).get(\"@first\", \"\"),\n",
        "            \"ref_title\": ref_info.get(\"ref-title\", {}).get(\"ref-titletext\", \"Title Not Available\"),\n",
        "            \"ref_sourcetitle\": ref_info.get(\"ref-sourcetitle\", \"\")\n",
        "        }\n",
        "\n",
        "        # Process authors and collaborations\n",
        "        ref_authors = ref_info.get(\"ref-authors\", {})\n",
        "        authors = ref_authors.get(\"author\", [])\n",
        "        if not isinstance(authors, list):\n",
        "            authors = [authors] if authors else []\n",
        "        reference_info[\"ref_authors\"] = [author.get(\"ce:indexed-name\", \"\") for author in authors]\n",
        "        reference_info[\"ref_authors_count\"] = len(reference_info[\"ref_authors\"])\n",
        "\n",
        "        collaborations = ref_authors.get(\"collaboration\", [])\n",
        "        if not isinstance(collaborations, list):\n",
        "            collaborations = [collaborations] if collaborations else []\n",
        "        reference_info[\"ref_collab\"] = [{\"collaboration_name\": collab.get(\"ce:text\", \"\")} for collab in collaborations]\n",
        "\n",
        "        bibliography_output[\"references\"].append(reference_info)\n",
        "\n",
        "    return bibliography_output\n"
      ],
      "metadata": {
        "id": "MW9sL16oMgYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### old fn"
      ],
      "metadata": {
        "id": "2U7PFkAtMfDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tail_info = bibrecord_data[\"tail\"]"
      ],
      "metadata": {
        "id": "UOlencg_iIt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Initialize the output dictionary for bibliography\n",
        "bibliography_output = {\n",
        "    \"refcount\": \"\",\n",
        "    \"references\": []\n",
        "}\n",
        "\n",
        "# Assume tail_info is defined and contains 'bibliography' data\n",
        "if \"bibliography\" in tail_info:\n",
        "    bibliography = tail_info[\"bibliography\"]\n",
        "    bibliography_output[\"refcount\"] = bibliography.get(\"@refcount\", \"0\")  # Get refcount safely\n",
        "\n",
        "    # Process each reference if the list is present\n",
        "    if \"reference\" in bibliography and isinstance(bibliography[\"reference\"], list):\n",
        "        for ref in bibliography[\"reference\"]:\n",
        "            reference_info = {\n",
        "                \"id\": ref.get(\"@id\", \"\"),\n",
        "                \"ref_fulltext\": ref.get(\"ref-fulltext\", \"\"),\n",
        "                \"ref_text\": ref.get(\"ce:source-text\", \"\"),  # Some might not have this field\n",
        "                \"ref_info\": {}\n",
        "            }\n",
        "\n",
        "            # Extract ref-info if available\n",
        "            if \"ref-info\" in ref:\n",
        "                ref_info = ref[\"ref-info\"]\n",
        "                reference_info[\"ref_info\"] = {\n",
        "                    \"ref_publicationyear\": ref_info.get(\"ref-publicationyear\", {}).get(\"@first\", \"\"),\n",
        "                    \"ref_title\": ref_info.get(\"ref-title\", {}).get(\"ref-titletext\", \"Title Not Available\"),\n",
        "                    \"ref_sourcetitle\": ref_info.get(\"ref-sourcetitle\", \"\")\n",
        "                }\n",
        "\n",
        "                # Extract authors or collaborations if available\n",
        "                if \"ref-authors\" in ref_info:\n",
        "                    if \"author\" in ref_info[\"ref-authors\"]:\n",
        "                        reference_info[\"ref_authors_count\"] = \"\"\n",
        "                        reference_info[\"ref_authors\"] = []\n",
        "                        authors = [author.get(\"ce:indexed-name\", \"\") for author in ref_info[\"ref-authors\"][\"author\"]]\n",
        "                        reference_info[\"ref_authors\"].extend(authors)  # Add all authors to the list\n",
        "                        reference_info[\"ref_authors_count\"] = len(reference_info[\"ref_authors\"])\n",
        "\n",
        "                    if \"collaboration\" in ref_info[\"ref-authors\"]:\n",
        "                        reference_info[\"ref_collab\"] = []\n",
        "                        # Handle multiple collaborations if it's a list, single if it's not\n",
        "                        collaborations = ref_info[\"ref-authors\"][\"collaboration\"]\n",
        "                        if isinstance(collaborations, list):\n",
        "                            for collab in collaborations:\n",
        "                                collab_info = {\"collaboration_name\": collab.get(\"ce:text\", \"\")}\n",
        "                                reference_info[\"ref_authors\"].append(collab_info)\n",
        "                        else:\n",
        "                            collab_info = {\"collaboration_name\": collaborations.get(\"ce:text\", \"\")}\n",
        "                            reference_info[\"ref_collab\"].append(collab_info)\n",
        "\n",
        "            bibliography_output[\"references\"].append(reference_info)\n",
        "\n",
        "# Print the extracted item-info data using json.dumps for pretty printing\n",
        "jprint(bibliography_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dt1iP8DiSs_",
        "outputId": "a4cdbd47-0224-4a43-8f86-00d5e252c294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"refcount\": \"20\",\n",
            "    \"references\": [\n",
            "        {\n",
            "            \"id\": \"1\",\n",
            "            \"ref_fulltext\": \"Brassier, A., Gobin, S., Arnoux, J.B., Valayannopoulos, V., Habarou, F., Kossorotoff, M., Servais, A., Barbier, V., Dubois, S., Touati, G., Barouki, R., Lesage, F., Dupic, L., Bonnefont, J.P., Ottolenghi, C., De Lonlay, P., Long-term outcomes in ornithine transcarbamylase deficiency: a series of 90 patients. Orphanet J. Rare Dis., 10, 2015, 58.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2015\",\n",
            "                \"ref_title\": \"Long-term outcomes in ornithine transcarbamylase deficiency: a series of 90 patients\",\n",
            "                \"ref_sourcetitle\": \"Orphanet J. Rare Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 16,\n",
            "            \"ref_authors\": [\n",
            "                \"Brassier A.\",\n",
            "                \"Gobin S.\",\n",
            "                \"Arnoux J.B.\",\n",
            "                \"Valayannopoulos V.\",\n",
            "                \"Habarou F.\",\n",
            "                \"Kossorotoff M.\",\n",
            "                \"Servais A.\",\n",
            "                \"Barbier V.\",\n",
            "                \"Dubois S.\",\n",
            "                \"Touati G.\",\n",
            "                \"Barouki R.\",\n",
            "                \"Lesage F.\",\n",
            "                \"Dupic L.\",\n",
            "                \"Bonnefont J.P.\",\n",
            "                \"Ottolenghi C.\",\n",
            "                \"De Lonlay P.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"2\",\n",
            "            \"ref_fulltext\": \"Brusilow, S.W., Maestri, N.E., Urea cycle disorders: diagnosis, pathophysiology, and therapy. Adv. Pediatr. Infect. Dis. 43 (1996), 127\\u2013170.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"1996\",\n",
            "                \"ref_title\": \"Urea cycle disorders: diagnosis, pathophysiology, and therapy\",\n",
            "                \"ref_sourcetitle\": \"Adv. Pediatr. Infect. Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 2,\n",
            "            \"ref_authors\": [\n",
            "                \"Brusilow S.W.\",\n",
            "                \"Maestri N.E.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"3\",\n",
            "            \"ref_fulltext\": \"Burlina, A.B., Peduto, A., Di Palma, A., Bellizzi, A., Sperli, D., Morrone, A., Burlina, A.P., An unusual clinical and biochemical presentation of ornithine transcarbamylase deficiency in a male patient. J. Inherit. Metab. Dis. 29 (2006), 179\\u2013181.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2006\",\n",
            "                \"ref_title\": \"An unusual clinical and biochemical presentation of ornithine transcarbamylase deficiency in a male patient\",\n",
            "                \"ref_sourcetitle\": \"J. Inherit. Metab. Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 7,\n",
            "            \"ref_authors\": [\n",
            "                \"Burlina A.B.\",\n",
            "                \"Peduto A.\",\n",
            "                \"Di Palma A.\",\n",
            "                \"Bellizzi A.\",\n",
            "                \"Sperli D.\",\n",
            "                \"Morrone A.\",\n",
            "                \"Burlina A.P.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"4\",\n",
            "            \"ref_fulltext\": \"Choi, J.H., Lee, B.H., Kim, J.H., Kim, G.H., Kim, Y.M., Cho, J., Cheon, C.K., Ko, J.M., Lee, J.H., Yoo, H.W., Clinical outcomes and the mutation spectrum of the OTC gene in patients with ornithine transcarbamylase deficiency. J. Hum. Genet. 60 (2015), 501\\u2013507.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2015\",\n",
            "                \"ref_title\": \"Clinical outcomes and the mutation spectrum of the OTC gene in patients with ornithine transcarbamylase deficiency\",\n",
            "                \"ref_sourcetitle\": \"J. Hum. Genet.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 10,\n",
            "            \"ref_authors\": [\n",
            "                \"Choi J.H.\",\n",
            "                \"Lee B.H.\",\n",
            "                \"Kim J.H.\",\n",
            "                \"Kim G.H.\",\n",
            "                \"Kim Y.M.\",\n",
            "                \"Cho J.\",\n",
            "                \"Cheon C.K.\",\n",
            "                \"Ko J.M.\",\n",
            "                \"Lee J.H.\",\n",
            "                \"Yoo H.W.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"5\",\n",
            "            \"ref_fulltext\": \"Gallagher, R.C., Lam, C., Wong, D., Cederbaum, S., Sokol, R.J., Significant hepatic involvement in patients with ornithine transcarbamylase deficiency. J. Pediatr. 164 (2014), 720\\u2013725 e6.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2014\",\n",
            "                \"ref_title\": \"Significant hepatic involvement in patients with ornithine transcarbamylase deficiency\",\n",
            "                \"ref_sourcetitle\": \"J. Pediatr.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 5,\n",
            "            \"ref_authors\": [\n",
            "                \"Gallagher R.C.\",\n",
            "                \"Lam C.\",\n",
            "                \"Wong D.\",\n",
            "                \"Cederbaum S.\",\n",
            "                \"Sokol R.J.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"6\",\n",
            "            \"ref_fulltext\": \"Gordon, N., Ornithine transcarbamylase deficiency: a urea cycle defect. Eur. J. Paediatr. Neurol. 7 (2003), 115\\u2013121.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2003\",\n",
            "                \"ref_title\": \"Ornithine transcarbamylase deficiency: a urea cycle defect\",\n",
            "                \"ref_sourcetitle\": \"Eur. J. Paediatr. Neurol.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 1,\n",
            "            \"ref_authors\": [\n",
            "                \"Gordon N.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"7\",\n",
            "            \"ref_fulltext\": \"Kim, S.H., Lee, J.S., Lim, B.C., Kim, K.J., Hwang, Y.S., Park, J.D., Cheon, J.E., Kim, I.O., Kim, B.N., Chae, J.H., A female carrier of ornithine carbamoyltransferase deficiency masquerading as attention deficit-hyperactivity disorder. Brain and Development 36 (2014), 734\\u2013737.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2014\",\n",
            "                \"ref_title\": \"A female carrier of ornithine carbamoyltransferase deficiency masquerading as attention deficit-hyperactivity disorder\",\n",
            "                \"ref_sourcetitle\": \"Brain and Development\"\n",
            "            },\n",
            "            \"ref_authors_count\": 10,\n",
            "            \"ref_authors\": [\n",
            "                \"Kim S.H.\",\n",
            "                \"Lee J.S.\",\n",
            "                \"Lim B.C.\",\n",
            "                \"Kim K.J.\",\n",
            "                \"Hwang Y.S.\",\n",
            "                \"Park J.D.\",\n",
            "                \"Cheon J.E.\",\n",
            "                \"Kim I.O.\",\n",
            "                \"Kim B.N.\",\n",
            "                \"Chae J.H.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"8\",\n",
            "            \"ref_fulltext\": \"Laemmle, A., Gallagher, R.C., Keogh, A., Stricker, T., Gautschi, M., Nuoffer, J.M., Baumgartner, M.R., Haberle, J., Frequency and pathophysiology of acute liver failure in Ornithine Transcarbamylase Deficiency (OTCD). PLoS One, 11, 2016, e0153358.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2016\",\n",
            "                \"ref_title\": \"Frequency and pathophysiology of acute liver failure in Ornithine Transcarbamylase Deficiency (OTCD)\",\n",
            "                \"ref_sourcetitle\": \"PLoS One\"\n",
            "            },\n",
            "            \"ref_authors_count\": 8,\n",
            "            \"ref_authors\": [\n",
            "                \"Laemmle A.\",\n",
            "                \"Gallagher R.C.\",\n",
            "                \"Keogh A.\",\n",
            "                \"Stricker T.\",\n",
            "                \"Gautschi M.\",\n",
            "                \"Nuoffer J.M.\",\n",
            "                \"Baumgartner M.R.\",\n",
            "                \"Haberle J.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"9\",\n",
            "            \"ref_fulltext\": \"Lindgren, V., de Martinville, B., Horwich, A.L., Rosenberg, L.E., Francke, U., Human ornithine transcarbamylase locus mapped to band Xp21.1 near the Duchenne muscular dystrophy locus. Science 226 (1984), 698\\u2013700.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"1984\",\n",
            "                \"ref_title\": \"Human ornithine transcarbamylase locus mapped to band Xp21.1 near the Duchenne muscular dystrophy locus\",\n",
            "                \"ref_sourcetitle\": \"Science\"\n",
            "            },\n",
            "            \"ref_authors_count\": 5,\n",
            "            \"ref_authors\": [\n",
            "                \"Lindgren V.\",\n",
            "                \"de Martinville B.\",\n",
            "                \"Horwich A.L.\",\n",
            "                \"Rosenberg L.E.\",\n",
            "                \"Francke U.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"10\",\n",
            "            \"ref_fulltext\": \"Martin-Hernandez, E., Aldamiz-Echevarria, L., Castejon-Ponce, E., Pedron-Giner, C., Couce, M.L., Serrano-Nieto, J., Pintos-Morell, G., Belanger-Quintana, A., Martinez-Pardo, M., Garcia-Silva, M.T., Quijada-Fraile, P., Vitoria-Minana, I., Dalmau, J., Lama-More, R.A., Bueno-Delgado, M.A., Del Toro-Riera, M., Garcia-Jimenez, I., Sierra-Corcoles, C., Ruiz-Pons, M., Pena-Quintana, L.J., Vives-Pinera, I., Morais, A., Balmaseda-Serrano, E., Meavilla, S., Sanjurjo-Crespo, P., Perez-Cerda, C., Urea cycle disorders in Spain: an observational, cross-sectional and multicentric study of 104 cases. Orphanet J. Rare Dis., 9, 2014, 187.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2014\",\n",
            "                \"ref_title\": \"Urea cycle disorders in Spain: an observational, cross-sectional and multicentric study of 104 cases\",\n",
            "                \"ref_sourcetitle\": \"Orphanet J. Rare Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 26,\n",
            "            \"ref_authors\": [\n",
            "                \"Martin-Hernandez E.\",\n",
            "                \"Aldamiz-Echevarria L.\",\n",
            "                \"Castejon-Ponce E.\",\n",
            "                \"Pedron-Giner C.\",\n",
            "                \"Couce M.L.\",\n",
            "                \"Serrano-Nieto J.\",\n",
            "                \"Pintos-Morell G.\",\n",
            "                \"Belanger-Quintana A.\",\n",
            "                \"Martinez-Pardo M.\",\n",
            "                \"Garcia-Silva M.T.\",\n",
            "                \"Quijada-Fraile P.\",\n",
            "                \"Vitoria-Minana I.\",\n",
            "                \"Dalmau J.\",\n",
            "                \"Lama-More R.A.\",\n",
            "                \"Bueno-Delgado M.A.\",\n",
            "                \"Del Toro-Riera M.\",\n",
            "                \"Garcia-Jimenez I.\",\n",
            "                \"Sierra-Corcoles C.\",\n",
            "                \"Ruiz-Pons M.\",\n",
            "                \"Pena-Quintana L.J.\",\n",
            "                \"Vives-Pinera I.\",\n",
            "                \"Morais A.\",\n",
            "                \"Balmaseda-Serrano E.\",\n",
            "                \"Meavilla S.\",\n",
            "                \"Sanjurjo-Crespo P.\",\n",
            "                \"Perez-Cerda C.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"11\",\n",
            "            \"ref_fulltext\": \"Rajabi, F., Rodan, L.H., Jonas, M.M., Soul, J.S., Ullrich, N.J., Wessel, A., Waisbren, S.E., Tan, W.H., Berry, G.T., Liver failure as the presentation of ornithine transcarbamylase deficiency in a 13-month-old female. JIMD Rep. 40 (2018), 17\\u201322.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2018\",\n",
            "                \"ref_title\": \"Liver failure as the presentation of ornithine transcarbamylase deficiency in a 13-month-old female\",\n",
            "                \"ref_sourcetitle\": \"JIMD Rep.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 9,\n",
            "            \"ref_authors\": [\n",
            "                \"Rajabi F.\",\n",
            "                \"Rodan L.H.\",\n",
            "                \"Jonas M.M.\",\n",
            "                \"Soul J.S.\",\n",
            "                \"Ullrich N.J.\",\n",
            "                \"Wessel A.\",\n",
            "                \"Waisbren S.E.\",\n",
            "                \"Tan W.H.\",\n",
            "                \"Berry G.T.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"12\",\n",
            "            \"ref_fulltext\": \"Ruegger, C.M., Lindner, M., Ballhausen, D., Baumgartner, M.R., Beblo, S., Das, A., Gautschi, M., Glahn, E.M., Grunert, S.C., Hennermann, J., Hochuli, M., Huemer, M., Karall, D., Kolker, S., Lachmann, R.H., Lotz-Havla, A., Moslinger, D., Nuoffer, J.M., Plecko, B., Rutsch, F., Santer, R., Spiekerkoetter, U., Staufner, C., Stricker, T., Wijburg, F.A., Williams, M., Burgard, P., Haberle, J., Cross-sectional observational study of 208 patients with non-classical urea cycle disorders. J. Inherit. Metab. Dis. 37 (2014), 21\\u201330.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2014\",\n",
            "                \"ref_title\": \"Cross-sectional observational study of 208 patients with non-classical urea cycle disorders\",\n",
            "                \"ref_sourcetitle\": \"J. Inherit. Metab. Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 28,\n",
            "            \"ref_authors\": [\n",
            "                \"Ruegger C.M.\",\n",
            "                \"Lindner M.\",\n",
            "                \"Ballhausen D.\",\n",
            "                \"Baumgartner M.R.\",\n",
            "                \"Beblo S.\",\n",
            "                \"Das A.\",\n",
            "                \"Gautschi M.\",\n",
            "                \"Glahn E.M.\",\n",
            "                \"Grunert S.C.\",\n",
            "                \"Hennermann J.\",\n",
            "                \"Hochuli M.\",\n",
            "                \"Huemer M.\",\n",
            "                \"Karall D.\",\n",
            "                \"Kolker S.\",\n",
            "                \"Lachmann R.H.\",\n",
            "                \"Lotz-Havla A.\",\n",
            "                \"Moslinger D.\",\n",
            "                \"Nuoffer J.M.\",\n",
            "                \"Plecko B.\",\n",
            "                \"Rutsch F.\",\n",
            "                \"Santer R.\",\n",
            "                \"Spiekerkoetter U.\",\n",
            "                \"Staufner C.\",\n",
            "                \"Stricker T.\",\n",
            "                \"Wijburg F.A.\",\n",
            "                \"Williams M.\",\n",
            "                \"Burgard P.\",\n",
            "                \"Haberle J.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"13\",\n",
            "            \"ref_fulltext\": \"Seminara, J., Tuchman, M., Krivitzky, L., Krischer, J., Lee, H.S., Lemons, C., Baumgartner, M., Cederbaum, S., Diaz, G.A., Feigenbaum, A., Gallagher, R.C., Harding, C.O., Kerr, D.S., Lanpher, B., Lee, B., Lichter-Konecki, U., McCandless, S.E., Merritt, J.L., Oster-Granite, M.L., Seashore, M.R., Stricker, T., Summar, M., Waisbren, S., Yudkoff, M., Batshaw, M.L., Establishing a consortium for the study of rare diseases: the Urea Cycle Disorders Consortium. Mol. Genet. Metab. 100:Suppl. 1 (2010), S97\\u2013105.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2010\",\n",
            "                \"ref_title\": \"Establishing a consortium for the study of rare diseases: the Urea Cycle Disorders Consortium\",\n",
            "                \"ref_sourcetitle\": \"Mol. Genet. Metab.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 25,\n",
            "            \"ref_authors\": [\n",
            "                \"Seminara J.\",\n",
            "                \"Tuchman M.\",\n",
            "                \"Krivitzky L.\",\n",
            "                \"Krischer J.\",\n",
            "                \"Lee H.S.\",\n",
            "                \"Lemons C.\",\n",
            "                \"Baumgartner M.\",\n",
            "                \"Cederbaum S.\",\n",
            "                \"Diaz G.A.\",\n",
            "                \"Feigenbaum A.\",\n",
            "                \"Gallagher R.C.\",\n",
            "                \"Harding C.O.\",\n",
            "                \"Kerr D.S.\",\n",
            "                \"Lanpher B.\",\n",
            "                \"Lee B.\",\n",
            "                \"Lichter-Konecki U.\",\n",
            "                \"McCandless S.E.\",\n",
            "                \"Merritt J.L.\",\n",
            "                \"Oster-Granite M.L.\",\n",
            "                \"Seashore M.R.\",\n",
            "                \"Stricker T.\",\n",
            "                \"Summar M.\",\n",
            "                \"Waisbren S.\",\n",
            "                \"Yudkoff M.\",\n",
            "                \"Batshaw M.L.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"14\",\n",
            "            \"ref_fulltext\": \"Shao, Y., Jiang, M., Lin, Y., Mei, H., Zhang, W., Cai, Y., Su, X., Hu, H., Li, X., Liu, L., Clinical and mutation analysis of 24 Chinese patients with ornithine transcarbamylase deficiency. Clin. Genet. 92 (2017), 318\\u2013322.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2017\",\n",
            "                \"ref_title\": \"Clinical and mutation analysis of 24 Chinese patients with ornithine transcarbamylase deficiency\",\n",
            "                \"ref_sourcetitle\": \"Clin. Genet.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 10,\n",
            "            \"ref_authors\": [\n",
            "                \"Shao Y.\",\n",
            "                \"Jiang M.\",\n",
            "                \"Lin Y.\",\n",
            "                \"Mei H.\",\n",
            "                \"Zhang W.\",\n",
            "                \"Cai Y.\",\n",
            "                \"Su X.\",\n",
            "                \"Hu H.\",\n",
            "                \"Li X.\",\n",
            "                \"Liu L.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"15\",\n",
            "            \"ref_fulltext\": \"Summar, M.L., Dobbelaere, D., Brusilow, S., Lee, B., Diagnosis, symptoms, frequency and mortality of 260 patients with urea cycle disorders from a 21-year, multicentre study of acute hyperammonaemic episodes. Acta Paediatr. 97 (2008), 1420\\u20131425.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2008\",\n",
            "                \"ref_title\": \"Diagnosis, symptoms, frequency and mortality of 260 patients with urea cycle disorders from a 21-year, multicentre study of acute hyperammonaemic episodes\",\n",
            "                \"ref_sourcetitle\": \"Acta Paediatr.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 4,\n",
            "            \"ref_authors\": [\n",
            "                \"Summar M.L.\",\n",
            "                \"Dobbelaere D.\",\n",
            "                \"Brusilow S.\",\n",
            "                \"Lee B.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"16\",\n",
            "            \"ref_fulltext\": \"Tuchman, M., Lee, B., Lichter-Konecki, U., Summar, M.L., Yudkoff, M., Cederbaum, S.D., Kerr, D.S., Diaz, G.A., Seashore, M.R., Lee, H.S., McCarter, R.J., Krischer, J.P., Batshaw, M.L., Urea Cycle Disorders Consortium of the Rare Diseases Clinical Research, N, Cross-sectional multicenter study of patients with urea cycle disorders in the United States. Mol. Genet. Metab. 94 (2008), 397\\u2013402.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2008\",\n",
            "                \"ref_title\": \"Cross-sectional multicenter study of patients with urea cycle disorders in the United States\",\n",
            "                \"ref_sourcetitle\": \"Mol. Genet. Metab.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 14,\n",
            "            \"ref_authors\": [\n",
            "                \"Tuchman M.\",\n",
            "                \"Lee B.\",\n",
            "                \"Lichter-Konecki U.\",\n",
            "                \"Summar M.L.\",\n",
            "                \"Yudkoff M.\",\n",
            "                \"Cederbaum S.D.\",\n",
            "                \"Kerr D.S.\",\n",
            "                \"Diaz G.A.\",\n",
            "                \"Seashore M.R.\",\n",
            "                \"Lee H.S.\",\n",
            "                \"McCarter R.J.\",\n",
            "                \"Krischer J.P.\",\n",
            "                \"Batshaw M.L.\",\n",
            "                \"Urea Cycle Disorders Consortium of the Rare Diseases Clinical Research, N\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"17\",\n",
            "            \"ref_fulltext\": \"Tuchman, M., Plante, R.J., Mutations and polymorphisms in the human ornithine transcarbamylase gene: mutation update addendum. Hum. Mutat. 5 (1995), 293\\u2013295.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"1995\",\n",
            "                \"ref_title\": \"Mutations and polymorphisms in the human ornithine transcarbamylase gene: mutation update addendum\",\n",
            "                \"ref_sourcetitle\": \"Hum. Mutat.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 2,\n",
            "            \"ref_authors\": [\n",
            "                \"Tuchman M.\",\n",
            "                \"Plante R.J.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"18\",\n",
            "            \"ref_fulltext\": \"Tummolo, A., Favia, V., Bellantuono, R., Bellino, V., Ranieri, A., Morrone, A., De Palo, T., Papadia, F., Successful early management of a female patient with a metabolic stroke due to ornithine transcarbamylase deficiency. Pediatr. Emerg. Care 29 (2013), 656\\u2013658.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2013\",\n",
            "                \"ref_title\": \"Successful early management of a female patient with a metabolic stroke due to ornithine transcarbamylase deficiency\",\n",
            "                \"ref_sourcetitle\": \"Pediatr. Emerg. Care\"\n",
            "            },\n",
            "            \"ref_authors_count\": 8,\n",
            "            \"ref_authors\": [\n",
            "                \"Tummolo A.\",\n",
            "                \"Favia V.\",\n",
            "                \"Bellantuono R.\",\n",
            "                \"Bellino V.\",\n",
            "                \"Ranieri A.\",\n",
            "                \"Morrone A.\",\n",
            "                \"De Palo T.\",\n",
            "                \"Papadia F.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"19\",\n",
            "            \"ref_fulltext\": \"Unsinn, C., Das, A., Valayannopoulos, V., Thimm, E., Beblo, S., Burlina, A., Konstantopoulou, V., Mayorandan, S., de Lonlay, P., Rennecke, J., Derbinski, J., Hoffmann, G.F., Haberle, J., Clinical course of 63 patients with neonatal onset urea cycle disorders in the years 2001\\u20132013. Orphanet J. Rare Dis., 11, 2016, 116.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2016\",\n",
            "                \"ref_title\": \"Clinical course of 63 patients with neonatal onset urea cycle disorders in the years 2001\\u20132013\",\n",
            "                \"ref_sourcetitle\": \"Orphanet J. Rare Dis.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 13,\n",
            "            \"ref_authors\": [\n",
            "                \"Unsinn C.\",\n",
            "                \"Das A.\",\n",
            "                \"Valayannopoulos V.\",\n",
            "                \"Thimm E.\",\n",
            "                \"Beblo S.\",\n",
            "                \"Burlina A.\",\n",
            "                \"Konstantopoulou V.\",\n",
            "                \"Mayorandan S.\",\n",
            "                \"de Lonlay P.\",\n",
            "                \"Rennecke J.\",\n",
            "                \"Derbinski J.\",\n",
            "                \"Hoffmann G.F.\",\n",
            "                \"Haberle J.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"20\",\n",
            "            \"ref_fulltext\": \"Yamaguchi, S., Brailey, L.L., Morizono, H., Bale, A.E., Tuchman, M., Mutations and polymorphisms in the human ornithine transcarbamylase (OTC) gene. Hum. Mutat. 27 (2006), 626\\u2013632.\",\n",
            "            \"ref_text\": \"\",\n",
            "            \"ref_info\": {\n",
            "                \"ref_publicationyear\": \"2006\",\n",
            "                \"ref_title\": \"Mutations and polymorphisms in the human ornithine transcarbamylase (OTC) gene\",\n",
            "                \"ref_sourcetitle\": \"Hum. Mutat.\"\n",
            "            },\n",
            "            \"ref_authors_count\": 5,\n",
            "            \"ref_authors\": [\n",
            "                \"Yamaguchi S.\",\n",
            "                \"Brailey L.L.\",\n",
            "                \"Morizono H.\",\n",
            "                \"Bale A.E.\",\n",
            "                \"Tuchman M.\"\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"yellow\">4.Coredata"
      ],
      "metadata": {
        "id": "aq2F0KV1pizI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_info_coredata = abstracts_info[\"coredata\"]"
      ],
      "metadata": {
        "id": "wCuhUgJbpkDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrate with web scrape"
      ],
      "metadata": {
        "id": "wFj9M7eMcYRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_citation_count(link):\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "    driver.get(link)\n",
        "    driver.implicitly_wait(5)\n",
        "    redirected_html = driver.page_source\n",
        "    driver.quit()\n",
        "\n",
        "    soup = BeautifulSoup(redirected_html, 'html.parser')\n",
        "    page_title_header = soup.find('span', id='pageTitleHeader')\n",
        "\n",
        "    if page_title_header:\n",
        "        text_inside_span = page_title_header.get_text(strip=True)\n",
        "        numbers = re.findall(r'\\d+', text_inside_span)\n",
        "        return numbers[0] if numbers else \"0\"\n",
        "    return \"0\"\n",
        "\n",
        "def process_coredata_info(abstract_info_coredata):\n",
        "    coredata_info_output = {\n",
        "        \"srctype\": abstract_info_coredata.get(\"srctype\", \"\"),\n",
        "        \"dc_description\": abstract_info_coredata.get(\"dc:description\", \"\"),\n",
        "        \"prism_aggregationType\": abstract_info_coredata.get(\"prism:aggregationType\", \"\"),\n",
        "        \"prism_url\": abstract_info_coredata.get(\"prism:url\", \"\"),\n",
        "        \"dc_title\": abstract_info_coredata.get(\"dc:title\", \"\"),\n",
        "        \"article_number\": abstract_info_coredata.get(\"article-number\", \"\"),\n",
        "        \"prism_publicationName\": abstract_info_coredata.get(\"prism:publicationName\", \"Publication Name Not Available\"),\n",
        "        \"dc_identifier\": abstract_info_coredata.get(\"dc:identifier\", \"\"),\n",
        "        \"dc_publisher\": abstract_info_coredata.get(\"dc:publisher\", \"\"),\n",
        "        \"dc_creator\": [],\n",
        "        \"links\": [],\n",
        "        \"citation_count\": \"0\"\n",
        "    }\n",
        "\n",
        "    if \"dc:creator\" in abstract_info_coredata and \"author\" in abstract_info_coredata[\"dc:creator\"]:\n",
        "        for author in abstract_info_coredata[\"dc:creator\"][\"author\"]:\n",
        "            author_info = {\n",
        "                \"preferred_name\": author.get(\"preferred-name\", {}),\n",
        "                \"auid\": author.get(\"@auid\", \"\"),\n",
        "                \"author_url\": author.get(\"author-url\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"dc_creator\"].append(author_info)\n",
        "\n",
        "    if \"link\" in abstract_info_coredata:\n",
        "        for link in abstract_info_coredata[\"link\"]:\n",
        "            link_info = {\n",
        "                \"rel\": link.get(\"@rel\", \"\"),\n",
        "                \"href\": link.get(\"@href\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"links\"].append(link_info)\n",
        "            if link.get(\"@rel\") == \"your_desired_relation_here\":  # Assuming you want a specific link\n",
        "                coredata_info_output[\"citation_count\"] = get_citation_count(link.get(\"@href\"))\n",
        "\n",
        "    return coredata_info_output"
      ],
      "metadata": {
        "id": "IYoEo6D2cWr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the fn"
      ],
      "metadata": {
        "id": "OcgyKsYecpn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_coredata_info(abstract_info_coredata):\n",
        "    # Initialize an output dictionary to store the extracted information\n",
        "    coredata_info_output = {\n",
        "        \"srctype\": abstract_info_coredata.get(\"srctype\", \"\"),\n",
        "        \"dc_description\": abstract_info_coredata.get(\"dc:description\", \"\"),\n",
        "        \"prism_aggregationType\": abstract_info_coredata.get(\"prism:aggregationType\", \"\"),\n",
        "        \"prism_url\": abstract_info_coredata.get(\"prism:url\", \"\"),\n",
        "        \"dc_title\": abstract_info_coredata.get(\"dc:title\", \"\"),\n",
        "        \"article_number\": abstract_info_coredata.get(\"article-number\", \"\"),\n",
        "        \"prism_publicationName\": abstract_info_coredata.get(\"prism:publicationName\", \"Publication Name Not Available\"),\n",
        "        \"dc_identifier\": abstract_info_coredata.get(\"dc:identifier\", \"\"),\n",
        "        \"dc_publisher\": abstract_info_coredata.get(\"dc:publisher\", \"\"),\n",
        "        \"dc_creator\": [],\n",
        "        \"links\": []\n",
        "    }\n",
        "\n",
        "    # Extract creator details\n",
        "    if \"dc:creator\" in abstract_info_coredata and \"author\" in abstract_info_coredata[\"dc:creator\"]:\n",
        "        for author in abstract_info_coredata[\"dc:creator\"][\"author\"]:\n",
        "            author_info = {\n",
        "                \"preferred_name\": author.get(\"preferred-name\", {}),\n",
        "                \"auid\": author.get(\"@auid\", \"\"),\n",
        "                \"author_url\": author.get(\"author-url\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"dc_creator\"].append(author_info)\n",
        "\n",
        "    # Extract links\n",
        "    if \"link\" in abstract_info_coredata:\n",
        "        for link in abstract_info_coredata[\"link\"]:\n",
        "            link_info = {\n",
        "                \"rel\": link.get(\"@rel\", \"\"),\n",
        "                \"href\": link.get(\"@href\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"links\"].append(link_info)\n",
        "\n",
        "    return coredata_info_output"
      ],
      "metadata": {
        "id": "plFKh5f0ppbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coredata_info = process_coredata_info(abstract_info_coredata)\n",
        "jprint(coredata_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA6uSdy8ZcNp",
        "outputId": "42bf62c3-8786-484f-f195-cfb2459b959b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"srctype\": \"j\",\n",
            "    \"dc_description\": \"Ornithine transcarbamylase deficiency (OTCD) is an X-linked urea cycle disorder affecting both males and females. Hemizygous males commonly present with severe hyperammonemic encephalopathy during the neonatal period. Heterozygous females have great phenotypic variability. The majority of female patients can manifest later in life or have unrecognized symptoms, making the diagnosis of OTCD in females very challenging. Here we report on three unrelated Thai female cases with OTCD presenting with different manifestations including aggressive behavior, acute liver failure and severe encephalopathy. Whole exome sequencing successfully identified disease-causing mutations in all three cases including two novel ones: the c.209_210delAA (p.Lys70Argfs*17) and the c.850T>A (p.Tyr284Asn). This study affirms variable symptoms in female patients with OTCD and emphasizes the importance of early recognition and prompt management for favorable outcomes. In addition, identification of two novel causative variants expands the genotypic spectrum of OTC.\",\n",
            "    \"prism_aggregationType\": \"Journal\",\n",
            "    \"prism_url\": \"https://api.elsevier.com/content/abstract/scopus_id/85053455291\",\n",
            "    \"dc_title\": \"The phenotypic and mutational spectrum of Thai female patients with ornithine transcarbamylase deficiency\",\n",
            "    \"article_number\": \"\",\n",
            "    \"prism_publicationName\": \"Gene\",\n",
            "    \"dc_identifier\": \"SCOPUS_ID:85053455291\",\n",
            "    \"dc_publisher\": \"Elsevier B.V.\",\n",
            "    \"dc_creator\": [\n",
            "        {\n",
            "            \"preferred_name\": {\n",
            "                \"ce:given-name\": \"Voranush\",\n",
            "                \"ce:initials\": \"V.\",\n",
            "                \"ce:surname\": \"Chongsrisawat\",\n",
            "                \"ce:indexed-name\": \"Chongsrisawat V.\"\n",
            "            },\n",
            "            \"auid\": \"7003640663\",\n",
            "            \"author_url\": \"https://api.elsevier.com/content/author/author_id/7003640663\"\n",
            "        }\n",
            "    ],\n",
            "    \"links\": [\n",
            "        {\n",
            "            \"rel\": \"self\",\n",
            "            \"href\": \"https://api.elsevier.com/content/abstract/scopus_id/85053455291\"\n",
            "        },\n",
            "        {\n",
            "            \"rel\": \"scopus\",\n",
            "            \"href\": \"https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85053455291&origin=inward\"\n",
            "        },\n",
            "        {\n",
            "            \"rel\": \"scopus-citedby\",\n",
            "            \"href\": \"https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85053455291&origin=inward\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.firefox.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "l = coredata_info['links'][2]['href']\n",
        "\n",
        "def get_citation_count(links):\n",
        "    # Set up Firefox options\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "\n",
        "    # Initialize WebDriver\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "\n",
        "    # URL to scrape\n",
        "    link = links\n",
        "\n",
        "    # Get the redirected URL\n",
        "    driver.get(link)\n",
        "\n",
        "    # Wait for the page to fully load (you may need to adjust the timeout)\n",
        "    driver.implicitly_wait(10)\n",
        "\n",
        "    # Get the HTML content of the redirected URL\n",
        "    redirected_html = driver.page_source\n",
        "\n",
        "    # Quit the WebDriver\n",
        "    driver.quit()\n",
        "\n",
        "    # Parse the HTML content with Beautiful Soup\n",
        "    soup = BeautifulSoup(redirected_html, 'html.parser')\n",
        "\n",
        "    # Find the span tag with id \"pageTitleHeader\"\n",
        "    page_title_header = soup.find('span', id='pageTitleHeader')\n",
        "\n",
        "    numbers = 0\n",
        "    # Extract the text from the span tag\n",
        "    if page_title_header:\n",
        "        text_inside_span = page_title_header.get_text(strip=True)\n",
        "        # Use regular expression to extract numbers\n",
        "        numbers = re.findall(r'\\d+', text_inside_span)\n",
        "        if numbers:\n",
        "            return numbers[0]\n",
        "        else:\n",
        "            print(\"No numbers found in the text.\")\n",
        "    else:\n",
        "        print(\"Span tag with id 'pageTitleHeader' not found.\")\n",
        "\n",
        "\n",
        "c = get_citation_count(l)\n",
        "print('citation count:', c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyvPH7c4Zl0D",
        "outputId": "b2636bf9-3b79-4251-b5c6-9e1df1fd7aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "citation count: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=\"yellow\"> 5.Authkeywords & SubjectAreas\n",
        "* **authkeywords**: each representing keywords selected by the authors of the research paper. These keywords are typically chosen to highlight the core topics, methods, and areas of focus within the research.\n",
        "* **subject_areas**: each representing what's the paper is associates with in each field of studies"
      ],
      "metadata": {
        "id": "ZaI9d3A4rpxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_auth_subject_data(abstract_info_authkeywords, abstract_info_subject):\n",
        "    # Prepare output dictionaries\n",
        "    authkeywords_output = {\"author_keyword\": []}\n",
        "    subject_areas_output = {\"subject_area\": []}\n",
        "\n",
        "    # Check and extract data for authkeywords\n",
        "    if abstract_info_authkeywords is not None and \"author-keyword\" in abstract_info_authkeywords:\n",
        "        author_keywords = abstract_info_authkeywords[\"author-keyword\"]\n",
        "        # Normalize to list if it's a single dictionary\n",
        "        if isinstance(author_keywords, dict):\n",
        "            author_keywords = [author_keywords]  # Convert a single dict to a list\n",
        "        # Extract keywords assuming a list of dictionaries now\n",
        "        authkeywords_output[\"author_keyword\"] = [keyword[\"$\"] for keyword in author_keywords]\n",
        "\n",
        "    # Check and extract data for subject-areas\n",
        "    if abstract_info_subject is not None and \"subject-area\" in abstract_info_subject:\n",
        "        subject_areas = abstract_info_subject[\"subject-area\"]\n",
        "        # Normalize to list if it's a single dictionary\n",
        "        if isinstance(subject_areas, dict):\n",
        "            subject_areas = [subject_areas]  # Convert a single dict to a list\n",
        "        subject_areas_output[\"subject_area\"] = [\n",
        "            {\n",
        "                \"name\": area[\"$\"],\n",
        "                \"code\": area[\"@code\"],\n",
        "                \"abbrev\": area[\"@abbrev\"]\n",
        "            } for area in subject_areas\n",
        "        ]\n",
        "\n",
        "    # Return both outputs as a tuple of dictionaries\n",
        "    return authkeywords_output, subject_areas_output\n"
      ],
      "metadata": {
        "id": "5V7x1nGVO_xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### old fn"
      ],
      "metadata": {
        "id": "-sBGK8wcO-iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the authkeywords is null or not\n",
        "keywordsNull = abstract_info_authkeywords is None"
      ],
      "metadata": {
        "id": "UoU9OwKMDz_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not keywordsNull:\n",
        "  # Extracting data for authkeywords\n",
        "  authkeywords_output = {\n",
        "      \"author_keyword\": [keyword[\"$\"] for keyword in abstract_info_authkeywords[\"author-keyword\"]]\n",
        "  }\n",
        "  jprint(authkeywords_output)\n",
        "else:\n",
        "  print(\"AuthKeywords is null\")\n",
        "# Extracting data for subject-areas\n",
        "subject_areas_output = {\n",
        "    \"subject_area\": [\n",
        "        {\n",
        "            \"name\": area[\"$\"],\n",
        "            \"code\": area[\"@code\"],\n",
        "            \"abbrev\": area[\"@abbrev\"]\n",
        "        } for area in abstract_info_subject[\"subject-area\"]\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Print the extracted data\n",
        "print(\"Subject Areas:\", json.dumps(subject_areas_output, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okFhrpZztE00",
        "outputId": "56db2105-7c9f-4c0e-e42c-f5827da794b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"author_keyword\": [\n",
            "        \"Female\",\n",
            "        \"Hyperammonemia\",\n",
            "        \"Novel mutations\",\n",
            "        \"Ornithine transcarbamylase deficiency\",\n",
            "        \"OTC\"\n",
            "    ]\n",
            "}\n",
            "Subject Areas: {\n",
            "    \"subject_area\": [\n",
            "        {\n",
            "            \"name\": \"Genetics\",\n",
            "            \"code\": \"1311\",\n",
            "            \"abbrev\": \"BIOC\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"Yellow\"> 6.IdxTerms\n",
        "* **weight**: This attribute is typically used to indicate the importance or relevance of a term within the context of the document (a > b > c)\n",
        "* **candidate**: This attribute usually indicates whether a term is being considered for a particular role or function within the document or system (for easier understanding -> is it important for out analysis n == no | y == yes)"
      ],
      "metadata": {
        "id": "z3m9glvuayqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the authkeywords is null or not\n",
        "idxNull = abstract_info_idxterms is None"
      ],
      "metadata": {
        "id": "xHoh3abGbepg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not idxNull:\n",
        "  jprint(abstract_info_idxterms)"
      ],
      "metadata": {
        "id": "tDBIYTG7a31V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "7a691a7f-3ddf-40df-eccf-4861bdcfae51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'idxNull' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03db44709c91>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0midxNull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mjprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_info_idxterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'idxNull' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process all data (in functions way)"
      ],
      "metadata": {
        "id": "ydi0-zwpR7RO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test dic"
      ],
      "metadata": {
        "id": "xQKgLw_y9HU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = range(2018, 2024)  # Years from 2018 to 2023\n",
        "for year in years:\n",
        "    # Construct the URL\n",
        "    url = f\"https://github.com/nnatchy/DSDE_Project/raw/main/{year}_test.zip\"\n",
        "    # Construct the wget command to download and rename the file directly\n",
        "    !wget {url} -O {year}.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AbnLtwUk8Fz",
        "outputId": "6baad089-8176-4b36-a849-c7b15e5f3bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-05 19:06:06--  https://github.com/nnatchy/DSDE_Project/raw/main/2018_test.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip [following]\n",
            "--2024-05-05 19:06:06--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2018_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6913340 (6.6M) [application/zip]\n",
            "Saving to: ‘2018.zip’\n",
            "\n",
            "2018.zip            100%[===================>]   6.59M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-05-05 19:06:07 (72.0 MB/s) - ‘2018.zip’ saved [6913340/6913340]\n",
            "\n",
            "--2024-05-05 19:06:07--  https://github.com/nnatchy/DSDE_Project/raw/main/2019_test.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip [following]\n",
            "--2024-05-05 19:06:07--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2019_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7328143 (7.0M) [application/zip]\n",
            "Saving to: ‘2019.zip’\n",
            "\n",
            "2019.zip            100%[===================>]   6.99M  42.7MB/s    in 0.2s    \n",
            "\n",
            "2024-05-05 19:06:07 (42.7 MB/s) - ‘2019.zip’ saved [7328143/7328143]\n",
            "\n",
            "--2024-05-05 19:06:07--  https://github.com/nnatchy/DSDE_Project/raw/main/2020_test.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip [following]\n",
            "--2024-05-05 19:06:08--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2020_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7393768 (7.1M) [application/zip]\n",
            "Saving to: ‘2020.zip’\n",
            "\n",
            "2020.zip            100%[===================>]   7.05M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-05-05 19:06:08 (78.2 MB/s) - ‘2020.zip’ saved [7393768/7393768]\n",
            "\n",
            "--2024-05-05 19:06:08--  https://github.com/nnatchy/DSDE_Project/raw/main/2021_test.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip [following]\n",
            "--2024-05-05 19:06:08--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2021_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7509824 (7.2M) [application/zip]\n",
            "Saving to: ‘2021.zip’\n",
            "\n",
            "2021.zip            100%[===================>]   7.16M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-05-05 19:06:09 (77.1 MB/s) - ‘2021.zip’ saved [7509824/7509824]\n",
            "\n",
            "--2024-05-05 19:06:09--  https://github.com/nnatchy/DSDE_Project/raw/main/2022_test.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip [following]\n",
            "--2024-05-05 19:06:09--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2022_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7154957 (6.8M) [application/zip]\n",
            "Saving to: ‘2022.zip’\n",
            "\n",
            "2022.zip            100%[===================>]   6.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-05-05 19:06:10 (71.8 MB/s) - ‘2022.zip’ saved [7154957/7154957]\n",
            "\n",
            "--2024-05-05 19:06:10--  https://github.com/nnatchy/DSDE_Project/raw/main/2023_test.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip [following]\n",
            "--2024-05-05 19:06:10--  https://raw.githubusercontent.com/nnatchy/DSDE_Project/main/2023_test.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7874655 (7.5M) [application/zip]\n",
            "Saving to: ‘2023.zip’\n",
            "\n",
            "2023.zip            100%[===================>]   7.51M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-05-05 19:06:11 (69.1 MB/s) - ‘2023.zip’ saved [7874655/7874655]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real dic"
      ],
      "metadata": {
        "id": "Hml3IdDB9Ja-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = range(2018, 2024)  # Years from 2018 to 2023\n",
        "for year in years:\n",
        "    # Construct the URL\n",
        "    url = f\"https://github.com/nnatchy/DSDE_Project/raw/main/{year}.zip\"\n",
        "    !wget {url} -O {year}.zip"
      ],
      "metadata": {
        "id": "fO3CdYTs9Li1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying"
      ],
      "metadata": {
        "id": "9eO5aTC99M6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_abstract_data(abstract_info):\n",
        "    try:\n",
        "        affiliation_info = abstract_info.get(\"affiliation\", [])\n",
        "        # Ensure affiliation_info is always a list\n",
        "        if isinstance(affiliation_info, dict):\n",
        "            affiliation_info = [affiliation_info]  # Normalize single dict to list\n",
        "        elif not isinstance(affiliation_info, list):\n",
        "            raise ValueError(\"affiliation data is neither a dictionary nor a list\")\n",
        "\n",
        "        affiliation_structure = {}\n",
        "        num_affi = num_city = num_country = 0\n",
        "        uni = []\n",
        "\n",
        "        for affiliation in affiliation_info:\n",
        "            # Ensure each affiliation is a dictionary\n",
        "            if not isinstance(affiliation, dict):\n",
        "                continue  # Skip if the affiliation is not a dictionary\n",
        "\n",
        "            country = affiliation.get(\"affiliation-country\", \"Unknown Country\")\n",
        "            city = affiliation.get(\"affiliation-city\", \"Unknown City\")\n",
        "            affi_name = affiliation.get(\"affilname\", \"\")\n",
        "\n",
        "            if \"University\" in affi_name:\n",
        "                uni.append(affi_name)\n",
        "\n",
        "            affil_dict = {\n",
        "                \"affilname\": affi_name,\n",
        "                \"href\": affiliation.get(\"@href\", \"\")\n",
        "            }\n",
        "\n",
        "            if country not in affiliation_structure:\n",
        "                affiliation_structure[country] = {}\n",
        "                num_country += 1\n",
        "\n",
        "            if city not in affiliation_structure[country]:\n",
        "                affiliation_structure[country][city] = []\n",
        "                num_city += 1\n",
        "\n",
        "            affiliation_structure[country][city].append(affil_dict)\n",
        "            num_affi += 1\n",
        "\n",
        "        affiliation_structure[\"Statistics\"] = {\n",
        "            \"num_affiliations\": num_affi,\n",
        "            \"num_university\": len(set(uni)),\n",
        "            \"num_country\": num_country,\n",
        "            \"num_city\": num_city\n",
        "        }\n",
        "        return affiliation_structure\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        # Depending on your use case, you might want to return an empty dict, raise the exception, or handle it differently\n",
        "        return {}\n"
      ],
      "metadata": {
        "id": "64sGdiQy8hxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_bibliographic_head_data(bibrecord_data):\n",
        "    head = bibrecord_data.get(\"head\", {})\n",
        "    head_output_data = {\n",
        "        \"author_groups\": [],\n",
        "        \"correspondence\": [],\n",
        "        \"enhancement\": [],\n",
        "        \"citation_title\": head.get(\"citation-title\", \"\"),\n",
        "        \"abstracts\": head.get(\"abstracts\", \"\")\n",
        "    }\n",
        "\n",
        "    # Process author groups\n",
        "    author_groups = head.get(\"author-group\", [])\n",
        "    if isinstance(author_groups, dict):\n",
        "        author_groups = [author_groups]\n",
        "\n",
        "    for author in author_groups:\n",
        "        affi = author.get(\"affiliation\", {})\n",
        "        org = affi.get(\"organization\", [])\n",
        "        organization_names = [org.get(\"$\", \"\")] if isinstance(org, dict) else [o.get(\"$\", \"\") for o in org if isinstance(o, dict)]\n",
        "        authors_list = author.get(\"author\", [])\n",
        "        authors_list = [authors_list] if isinstance(authors_list, dict) else authors_list\n",
        "\n",
        "        for person in authors_list:\n",
        "            author_info = {\n",
        "                \"indexed-name\": person.get(\"preferred-name\", {}).get(\"ce:indexed-name\", \"\"),\n",
        "                \"seq\": person.get(\"@seq\", \"\"),\n",
        "                \"auid\": person.get(\"@auid\", \"\"),\n",
        "                \"affiliation\": {\n",
        "                    \"affiliation_id\": affi.get(\"@afid\", \"\"),\n",
        "                    \"dpt_id\": affi.get(\"@dptid\", \"\"),\n",
        "                    \"country\": affi.get(\"country\", \"\"),\n",
        "                    \"organization\": organization_names\n",
        "                }\n",
        "            }\n",
        "            head_output_data[\"author_groups\"].append(author_info)\n",
        "\n",
        "    # Process correspondence\n",
        "    correspondence_data = head.get(\"correspondence\", [])\n",
        "    if not isinstance(correspondence_data, list):\n",
        "        correspondence_data = [correspondence_data] if correspondence_data else []\n",
        "\n",
        "    for item in correspondence_data:\n",
        "        if isinstance(item, dict):\n",
        "            person_info = item.get(\"person\", {})\n",
        "            correspondence_info = {\n",
        "                \"affiliation\": {\n",
        "                    \"organization\": [aff.get(\"$\", \"\") for aff in item.get(\"affiliation\", {}).get(\"organization\", []) if isinstance(aff, dict)]\n",
        "                },\n",
        "                \"person\": {\n",
        "                    \"given_name\": person_info.get(\"ce:given-name\", \"\"),\n",
        "                    \"initials\": person_info.get(\"ce:initials\", \"\"),\n",
        "                    \"surname\": person_info.get(\"ce:surname\", \"\"),\n",
        "                    \"indexed_name\": person_info.get(\"ce:indexed-name\", \"\")\n",
        "                }\n",
        "            }\n",
        "            head_output_data[\"correspondence\"].append(correspondence_info)\n",
        "\n",
        "    # Enhancements\n",
        "    enhancements = head.get(\"enhancement\", {})\n",
        "    classifications = enhancements.get(\"classificationgroup\", {}).get(\"classifications\", [])\n",
        "    if isinstance(classifications, dict):\n",
        "        classifications = [classifications]\n",
        "\n",
        "    for classification in classifications:\n",
        "        class_content = classification.get(\"classification\", [])\n",
        "        class_content = [class_content] if isinstance(class_content, dict) else class_content\n",
        "        class_info = {\n",
        "            \"type\": classification.get(\"@type\"),\n",
        "            \"classifications\": [item.get(\"$\", item) for item in class_content if isinstance(item, dict)]\n",
        "        }\n",
        "        head_output_data[\"enhancement\"].append(class_info)\n",
        "\n",
        "    # Source information\n",
        "    source_info = head.get(\"source\", {})\n",
        "    website_info = source_info.get(\"website\", {})\n",
        "    website_address = \"\"\n",
        "    if isinstance(website_info, list):\n",
        "        # Assuming the first item in the list contains the 'ce:e-address' if the list is not structured as expected\n",
        "        website_address = website_info[0].get(\"ce:e-address\", {}).get(\"$\", \"\") if isinstance(website_info[0], dict) else \"\"\n",
        "    elif isinstance(website_info, dict):\n",
        "        website_address = website_info.get(\"ce:e-address\", {}).get(\"$\", \"\")\n",
        "\n",
        "    head_output_data[\"source\"] = {\n",
        "        \"website_address\": website_address,\n",
        "        \"publication_date\": source_info.get(\"publicationdate\", \"\"),\n",
        "        \"publisher_name\": source_info.get(\"publisher\", {}).get(\"publishername\", \"\")\n",
        "    }\n",
        "\n",
        "    return head_output_data\n",
        "\n",
        "def process_bibliography_item_info_data(bibrecord_data):\n",
        "    item_info_output = {\n",
        "        \"external_source\": \"\",\n",
        "        \"history\": {}\n",
        "    }\n",
        "\n",
        "    item_info = bibrecord_data.get(\"item-info\", {})\n",
        "    if not item_info:  # Check if item_info is empty or None\n",
        "        return item_info_output\n",
        "\n",
        "    item_info_output[\"external_source\"] = item_info.get(\"external-source\", \"\")\n",
        "\n",
        "    history = item_info.get(\"history\", {})\n",
        "    date_created = history.get(\"date-created\", {})\n",
        "    item_info_output[\"history\"] = {\n",
        "        \"day\": date_created.get(\"@day\", \"\"),\n",
        "        \"timestamp\": date_created.get(\"@timestamp\", \"\"),\n",
        "        \"year\": date_created.get(\"@year\", \"\"),\n",
        "        \"month\": date_created.get(\"@month\", \"\")\n",
        "    }\n",
        "\n",
        "    return item_info_output\n",
        "\n",
        "def process_bibliography_tail_data(bibrecord_data):\n",
        "    # Ensure 'tail' is a dictionary before proceeding\n",
        "    tail_info = bibrecord_data.get(\"tail\", {})\n",
        "\n",
        "    bibliography_output = {\n",
        "        \"refcount\": \"\",\n",
        "        \"references\": []\n",
        "    }\n",
        "\n",
        "    if not tail_info:  # Check if tail_info is empty or None\n",
        "        return bibliography_output\n",
        "\n",
        "    bibliography = tail_info.get(\"bibliography\", {})\n",
        "    bibliography_output[\"refcount\"] = bibliography.get(\"@refcount\", \"0\")\n",
        "\n",
        "    # Handle references\n",
        "    references = bibliography.get(\"reference\", [])\n",
        "    if not isinstance(references, list):\n",
        "        references = [references] if references else []\n",
        "\n",
        "    for ref in references:\n",
        "        reference_info = {\n",
        "            \"id\": ref.get(\"@id\", \"\"),\n",
        "            \"ref_fulltext\": ref.get(\"ref-fulltext\", \"\"),\n",
        "            \"ref_text\": ref.get(\"ce:source-text\", \"\"),\n",
        "            \"ref_info\": {},\n",
        "            \"ref_authors\": [],\n",
        "            \"ref_authors_count\": \"\",\n",
        "            \"ref_collab\": []\n",
        "        }\n",
        "\n",
        "        ref_info = ref.get(\"ref-info\", {})\n",
        "        reference_info[\"ref_info\"] = {\n",
        "            \"ref_publicationyear\": ref_info.get(\"ref-publicationyear\", {}).get(\"@first\", \"\"),\n",
        "            \"ref_title\": ref_info.get(\"ref-title\", {}).get(\"ref-titletext\", \"Title Not Available\"),\n",
        "            \"ref_sourcetitle\": ref_info.get(\"ref-sourcetitle\", \"\")\n",
        "        }\n",
        "\n",
        "        # Process authors and collaborations\n",
        "        ref_authors = ref_info.get(\"ref-authors\", {})\n",
        "        authors = ref_authors.get(\"author\", [])\n",
        "        if not isinstance(authors, list):\n",
        "            authors = [authors] if authors else []\n",
        "        reference_info[\"ref_authors\"] = [author.get(\"ce:indexed-name\", \"\") for author in authors]\n",
        "        reference_info[\"ref_authors_count\"] = len(reference_info[\"ref_authors\"])\n",
        "\n",
        "        collaborations = ref_authors.get(\"collaboration\", [])\n",
        "        if not isinstance(collaborations, list):\n",
        "            collaborations = [collaborations] if collaborations else []\n",
        "        reference_info[\"ref_collab\"] = [{\"collaboration_name\": collab.get(\"ce:text\", \"\")} for collab in collaborations]\n",
        "\n",
        "        bibliography_output[\"references\"].append(reference_info)\n",
        "\n",
        "    return bibliography_output\n"
      ],
      "metadata": {
        "id": "82AT5NN58rOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_citation_count(link):\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    driver = webdriver.Firefox(options=options)\n",
        "    driver.get(link)\n",
        "    driver.implicitly_wait(5)\n",
        "    redirected_html = driver.page_source\n",
        "    driver.quit()\n",
        "\n",
        "    soup = BeautifulSoup(redirected_html, 'html.parser')\n",
        "    page_title_header = soup.find('span', id='pageTitleHeader')\n",
        "\n",
        "    if page_title_header:\n",
        "        text_inside_span = page_title_header.get_text(strip=True)\n",
        "        numbers = re.findall(r'\\d+', text_inside_span)\n",
        "        return numbers[0] if numbers else \"0\"\n",
        "    return \"0\"\n",
        "\n",
        "def process_coredata_info(abstract_info_coredata):\n",
        "    coredata_info_output = {\n",
        "        \"srctype\": abstract_info_coredata.get(\"srctype\", \"\"),\n",
        "        \"dc_description\": abstract_info_coredata.get(\"dc:description\", \"\"),\n",
        "        \"prism_aggregationType\": abstract_info_coredata.get(\"prism:aggregationType\", \"\"),\n",
        "        \"prism_url\": abstract_info_coredata.get(\"prism:url\", \"\"),\n",
        "        \"dc_title\": abstract_info_coredata.get(\"dc:title\", \"\"),\n",
        "        \"article_number\": abstract_info_coredata.get(\"article-number\", \"\"),\n",
        "        \"prism_publicationName\": abstract_info_coredata.get(\"prism:publicationName\", \"Publication Name Not Available\"),\n",
        "        \"dc_identifier\": abstract_info_coredata.get(\"dc:identifier\", \"\"),\n",
        "        \"dc_publisher\": abstract_info_coredata.get(\"dc:publisher\", \"\"),\n",
        "        \"dc_creator\": [],\n",
        "        \"links\": [],\n",
        "        \"citation_count\": \"0\"\n",
        "    }\n",
        "\n",
        "    if \"dc:creator\" in abstract_info_coredata and \"author\" in abstract_info_coredata[\"dc:creator\"]:\n",
        "        for author in abstract_info_coredata[\"dc:creator\"][\"author\"]:\n",
        "            author_info = {\n",
        "                \"preferred_name\": author.get(\"preferred-name\", {}),\n",
        "                \"auid\": author.get(\"@auid\", \"\"),\n",
        "                \"author_url\": author.get(\"author-url\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"dc_creator\"].append(author_info)\n",
        "\n",
        "    if \"link\" in abstract_info_coredata:\n",
        "        for link in abstract_info_coredata[\"link\"]:\n",
        "            link_info = {\n",
        "                \"rel\": link.get(\"@rel\", \"\"),\n",
        "                \"href\": link.get(\"@href\", \"\")\n",
        "            }\n",
        "            coredata_info_output[\"links\"].append(link_info)\n",
        "            if link.get(\"@rel\") == \"your_desired_relation_here\":  # Assuming you want a specific link\n",
        "                coredata_info_output[\"citation_count\"] = get_citation_count(link.get(\"@href\"))\n",
        "\n",
        "    return coredata_info_output"
      ],
      "metadata": {
        "id": "dc1i800i86fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_auth_subject_data(abstract_info_authkeywords, abstract_info_subject):\n",
        "    # Prepare output dictionaries\n",
        "    authkeywords_output = {\"author_keyword\": []}\n",
        "    subject_areas_output = {\"subject_area\": []}\n",
        "\n",
        "    # Check and extract data for authkeywords\n",
        "    if abstract_info_authkeywords is not None and \"author-keyword\" in abstract_info_authkeywords:\n",
        "        author_keywords = abstract_info_authkeywords[\"author-keyword\"]\n",
        "        # Normalize to list if it's a single dictionary\n",
        "        if isinstance(author_keywords, dict):\n",
        "            author_keywords = [author_keywords]  # Convert a single dict to a list\n",
        "        # Extract keywords assuming a list of dictionaries now\n",
        "        authkeywords_output[\"author_keyword\"] = [keyword[\"$\"] for keyword in author_keywords]\n",
        "\n",
        "    # Check and extract data for subject-areas\n",
        "    if abstract_info_subject is not None and \"subject-area\" in abstract_info_subject:\n",
        "        subject_areas = abstract_info_subject[\"subject-area\"]\n",
        "        # Normalize to list if it's a single dictionary\n",
        "        if isinstance(subject_areas, dict):\n",
        "            subject_areas = [subject_areas]  # Convert a single dict to a list\n",
        "        subject_areas_output[\"subject_area\"] = [\n",
        "            {\n",
        "                \"name\": area[\"$\"],\n",
        "                \"code\": area[\"@code\"],\n",
        "                \"abbrev\": area[\"@abbrev\"]\n",
        "            } for area in subject_areas\n",
        "        ]\n",
        "\n",
        "    # Return both outputs as a tuple of dictionaries\n",
        "    return authkeywords_output, subject_areas_output\n"
      ],
      "metadata": {
        "id": "goKrjoy28-W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "def process_files(year_range, base_path):\n",
        "    batch_years = []\n",
        "    for year in year_range:\n",
        "        # Determine the directory pattern based on the year\n",
        "        year_directory = f\"{base_path}/{year}/\" if year == 2018 else f\"{base_path}/{year}/\"\n",
        "\n",
        "        # Ensure the year directory exists and create if not\n",
        "        os.makedirs(year_directory, exist_ok=True)\n",
        "\n",
        "        # Check for zip files in the base path and unzip them to the year directory\n",
        "        zip_file_path = os.path.join(base_path, f'{year}.zip')\n",
        "        if os.path.exists(zip_file_path):\n",
        "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(year_directory)\n",
        "                print(f\"Extracted {zip_file_path} to {year_directory}\")\n",
        "\n",
        "        # Process JSON files in the unzipped directory\n",
        "        batch_data = []\n",
        "        print(\"cur year:\", year_directory)\n",
        "        for filename in os.listdir(year_directory):\n",
        "            if filename == \"__MACOSX\": continue\n",
        "            file_copy = os.path.join(year_directory, filename)\n",
        "            print(\"cur cop:\", file_copy)\n",
        "            for file_elem in os.listdir(file_copy):\n",
        "              if file_elem == '.DS_Store': continue\n",
        "              file_path = os.path.join(file_copy, file_elem)\n",
        "              print(\"cur path:\", file_path)\n",
        "              with open(file_path, 'r') as file:\n",
        "                  json_data = json.load(file)\n",
        "                  # Assuming 'abstracts-retrieval-response' is the key where the data starts\n",
        "                  abstracts_info = json_data.get(\"abstracts-retrieval-response\", {})\n",
        "\n",
        "                  # look into the unimportant ones as well\n",
        "                  affiliation_info = abstracts_info[\"affiliation\"]\n",
        "                  language = abstracts_info[\"language\"]\n",
        "\n",
        "                  abstracts_info_item = abstracts_info[\"item\"]\n",
        "                  bibrecord_data = abstracts_info_item[\"bibrecord\"]\n",
        "\n",
        "                  abstract_info_coredata = abstracts_info[\"coredata\"]\n",
        "\n",
        "                  abstract_info_idxterms = abstracts_info[\"idxterms\"]\n",
        "\n",
        "                  abstract_info_authkeywords = abstracts_info.get(\"authkeywords\", [])  # Default to empty list if null\n",
        "                  abstract_info_subject = abstracts_info.get(\"subject-areas\", [])  # Default to empty list if null\n",
        "                  # Call your data processing functions here and collect results\n",
        "\n",
        "                  affiliation_data = process_abstract_data(affiliation_info)\n",
        "                  bibliographic_data = process_bibliographic_head_data(bibrecord_data)\n",
        "                  item_info_data = process_bibliography_item_info_data(bibrecord_data)\n",
        "                  bibliography_tail_data = process_bibliography_tail_data(bibrecord_data)\n",
        "                  core_data_info = process_coredata_info(abstract_info_coredata)\n",
        "                  authkeywords_output, subject_areas_output = process_auth_subject_data(abstract_info_authkeywords, abstract_info_subject)\n",
        "\n",
        "                  processed_data = {\n",
        "                      \"affiliationData\": affiliation_data,\n",
        "                      \"bibliographicData\": bibliographic_data,\n",
        "                      \"itemInfoData\": item_info_data,\n",
        "                      \"bibliographyTailData\": bibliography_tail_data,\n",
        "                      \"coreDataInfo\": core_data_info,\n",
        "                      \"authKeywordsInfo\": authkeywords_output,\n",
        "                      \"subjectAreasInfo\": subject_areas_output,\n",
        "                  }\n",
        "                  batch_data.append(processed_data)\n",
        "\n",
        "        batch_years.append(batch_data)\n",
        "\n",
        "    return batch_years\n",
        "\n",
        "# Example to call the function\n",
        "by = process_files(range(2018, 2024), \".\")\n",
        "pprint.pprint(by[0])  # Use pprint to print the final data structure nicely"
      ],
      "metadata": {
        "id": "Fdj_jg_sR90q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}