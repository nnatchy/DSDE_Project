{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e79b6d-5de9-48f4-a71e-b96dd6b04ff4",
   "metadata": {},
   "source": [
    "# Install lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e40d6c5-1c97-40a7-b7af-05bdbea703fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2616d199-76ab-45c4-8a20-3c320e0783b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# use this function to print the json with the indent=4\n",
    "def jprint(data):\n",
    "  print(json.dumps(data,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6c86c-9126-4d3c-9c99-c66d7741b0bb",
   "metadata": {},
   "source": [
    "# Spark for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a18935d5-f30d-452c-9423-53d9e84b17f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+------------+-------------+--------+------------------------+\n",
      "|id       |publicDate|source|coAuthorship|citationCount|refCount|Class                   |\n",
      "+---------+----------+------+------------+-------------+--------+------------------------+\n",
      "|201800282|15/11/2018|1     |3           |29           |89      |[ENER, PHYS]            |\n",
      "|201800276|17/11/2018|1     |5           |11           |18      |[CHEM, BIOC, AGRI]      |\n",
      "|201800044|11/12/2018|1     |5           |76           |60      |[ENVI, CENG, MATE, ENER]|\n",
      "|201800249|01/12/2018|1     |4           |9            |39      |[EART, AGRI]            |\n",
      "|201800043|12/12/2018|1     |2303        |59           |101     |[PHYS]                  |\n",
      "|201800271|20/11/2018|1     |2           |53           |21      |[COMP]                  |\n",
      "|201800285|14/11/2018|1     |1           |5            |16      |[AGRI, ENVI]            |\n",
      "|201800088|01/12/2018|1     |32          |23           |107     |[PHYS, EART]            |\n",
      "|201800075|01/12/2018|1     |2           |NULL         |NULL    |[VETE]                  |\n",
      "|201800247|01/12/2018|1     |5           |8            |48      |[MATE, ENGI]            |\n",
      "|201800081|01/12/2018|1     |7           |8            |22      |[NEUR, MEDI]            |\n",
      "|201800278|16/11/2018|1     |2           |1            |7       |[PHYS]                  |\n",
      "|201800086|01/12/2018|1     |2           |0            |16      |[ENER, ENGI, COMP]      |\n",
      "|201800240|01/12/2018|1     |5           |19           |46      |[MULT]                  |\n",
      "|201800072|01/12/2018|1     |4           |NULL         |33      |[VETE]                  |\n",
      "|201800019|19/12/2018|1     |3           |0            |31      |[BUSI, ECON, ENVI]      |\n",
      "|201800026|19/12/2018|1     |3           |2            |3       |[PHYS]                  |\n",
      "|201800214|01/12/2018|1     |6           |14           |23      |[IMMU, VETE]            |\n",
      "|201800213|01/12/2018|1     |4           |79           |52      |[CHEM]                  |\n",
      "|201800021|19/12/2018|1     |3           |4            |17      |[PHYS]                  |\n",
      "+---------+----------+------+------------+-------------+--------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, regexp_replace\n",
    "\n",
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DSDE2024\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the CSV file\n",
    "df = spark.read.option(\"header\", \"true\").csv('../out_spark/before_spark/input_concatenated.csv')\n",
    "\n",
    "# Remove brackets and single quotes, then split into array\n",
    "df = df.withColumn(\"Class\", regexp_replace(col(\"Class\"), \"[\\\\[\\\\]'']\", \"\"))  # Remove [ ], and '\n",
    "df = df.withColumn(\"Class\", split(col(\"Class\"), \",\\s*\"))  # Split into array\n",
    "\n",
    "# Show the transformed DataFrame to verify\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63978397-377c-4c00-a192-19ce1f8b16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e82b34f-1dfe-45a3-ad78-7296f28ea493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f99cec-ab8c-48f3-bde5-35ab6bcc2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast type accordingly\n",
    "df = df.withColumn('citationCount', df.citationCount.cast('int'))\n",
    "df = df.withColumn('coAuthorship', df.coAuthorship.cast('int'))\n",
    "df = df.withColumn('refCount', df.refCount.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bed7bef-0f01-4c98-bbd0-17ba00d663ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, min, max, countDistinct, explode, split, col, round, sum\n",
    "\n",
    "max_values = df.agg(\n",
    "    max(\"citationCount\").alias(\"maxCitation\"),\n",
    "    max(\"refCount\").alias(\"maxRef\"),\n",
    "    max(\"coAuthorship\").alias(\"maxCoAuthor\")\n",
    ").collect()[0]\n",
    "\n",
    "# max value for each feature for normalization\n",
    "max_citation = max_values[\"maxCitation\"]\n",
    "max_ref = max_values[\"maxRef\"]\n",
    "max_coauthor = max_values[\"maxCoAuthor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff27930-d46a-431e-ba8c-9432ad8a4c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all the class: 27\n",
      "+-----+-----+\n",
      "|Genre|count|\n",
      "+-----+-----+\n",
      "| COMP|  131|\n",
      "| MATE|  141|\n",
      "| IMMU|   87|\n",
      "| ARTS|   20|\n",
      "| PHYS|  188|\n",
      "| HEAL|   16|\n",
      "| PSYC|    9|\n",
      "| BIOC|  202|\n",
      "| NEUR|   26|\n",
      "| VETE|   66|\n",
      "| ENGI|  213|\n",
      "| PHAR|   60|\n",
      "| MEDI|  483|\n",
      "| ECON|   32|\n",
      "| MATH|   48|\n",
      "| MULT|  299|\n",
      "| ENVI|  159|\n",
      "| DECI|   23|\n",
      "| AGRI|  149|\n",
      "| ENER|   93|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find all Class\n",
    "genre_counts = df.withColumn(\"Genre\", explode(col(\"Class\")))\\\n",
    "                 .groupBy(\"Genre\")\\\n",
    "                 .count()  \n",
    "\n",
    "print('number of all the class:', genre_counts.count())\n",
    "genre_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "424773a6-1b80-49e0-a831-9dfcb0299c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode the class\n",
    "exploded_df = df.withColumn(\"Class\", explode(col(\"Class\")))\n",
    "# exploded_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "027438d6-93ac-471f-ba68-f534a0713f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2852\n",
      "+---------+----------+------+------------+-------------+--------+-----+\n",
      "|       id|publicDate|source|coAuthorship|citationCount|refCount|Class|\n",
      "+---------+----------+------+------------+-------------+--------+-----+\n",
      "|201800000|31/12/2018|     1|           2|            1|      76| MEDI|\n",
      "|201800001|31/12/2018|     1|           2|            1|       4| ENGI|\n",
      "|201800001|31/12/2018|     1|           2|            1|       4| MATE|\n",
      "|201800002|31/12/2018|     1|           4|           21|      42| CHEM|\n",
      "|201800002|31/12/2018|     1|           4|           21|      42| CENG|\n",
      "+---------+----------+------+------------+-------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop na for invalid rows\n",
    "cleaned_df = exploded_df.dropna()\n",
    "print(cleaned_df.count())\n",
    "cleaned_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037084a9-ac9e-4954-8709-c6e6a647bb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+------------+-------------+--------+-----+------+\n",
      "|       id|publicDate|source|coAuthorship|citationCount|refCount|Class| Score|\n",
      "+---------+----------+------+------------+-------------+--------+-----+------+\n",
      "|201800000|31/12/2018|     1|           2|            1|      76| MEDI| 0.264|\n",
      "|201800001|31/12/2018|     1|           2|            1|       4| ENGI|0.0203|\n",
      "|201800001|31/12/2018|     1|           2|            1|       4| MATE|0.0203|\n",
      "|201800002|31/12/2018|     1|           4|           21|      42| CHEM|0.2681|\n",
      "|201800002|31/12/2018|     1|           4|           21|      42| CENG|0.2681|\n",
      "|201800002|31/12/2018|     1|           4|           21|      42| ENGI|0.2681|\n",
      "|201800003|31/12/2018|     1|           8|           44|      45| CHEM| 0.416|\n",
      "|201800003|31/12/2018|     1|           8|           44|      45| PHYS| 0.416|\n",
      "|201800003|31/12/2018|     1|           8|           44|      45| MATE| 0.416|\n",
      "|201800004|31/12/2018|     1|           6|           75|      55| CHEM|0.6324|\n",
      "+---------+----------+------+------------+-------------+--------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the score for each paper\n",
    "cleaned_df = cleaned_df.withColumn(\n",
    "    \"Score\",\n",
    "    round(\n",
    "        col(\"source\") * (\n",
    "            0.4 * (col(\"citationCount\") / max_citation * 10) +\n",
    "            0.2 * (col(\"refCount\") / max_ref * 10) +\n",
    "            0.1 * (col(\"coAuthorship\") / max_coauthor * 10)\n",
    "        ), 4\n",
    "    )\n",
    ")\n",
    "\n",
    "cleaned_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb2e9eb-c9ae-4a35-8096-fb7ebe15ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+-----------+-----------+\n",
      "|Class|Year|Quarter|Total Score|Paper Count|\n",
      "+-----+----+-------+-----------+-----------+\n",
      "| IMMU|2019|      3|     2.3568|          1|\n",
      "| NEUR|2020|      2|     1.8807|          1|\n",
      "| MEDI|2019|      4|   270.1514|        122|\n",
      "| PHYS|2018|      4|    23.7444|         10|\n",
      "| MEDI|2023|      3|      1.208|          2|\n",
      "| PHYS|2023|      1|     7.0614|          1|\n",
      "| CHEM|2021|      4|    30.0819|          9|\n",
      "| MEDI|2021|      2|      4.196|          3|\n",
      "| COMP|2022|      4|    32.7025|         10|\n",
      "| MEDI|2023|      4|   640.2262|        117|\n",
      "| PHYS|2022|      4|    34.0808|         10|\n",
      "| NEUR|2021|      4|    32.2437|         10|\n",
      "| COMP|2020|      4|    22.6319|          8|\n",
      "| IMMU|2022|      3|     7.7949|          1|\n",
      "| BIOC|2019|      4|     37.203|         18|\n",
      "| MEDI|2023|      2|    11.4988|          8|\n",
      "| IMMU|2023|      4|    48.8768|         10|\n",
      "| BIOC|2023|      4|    87.5925|         17|\n",
      "| NEUR|2023|      2|      1.808|          1|\n",
      "| IMMU|2018|      4|    19.7245|         10|\n",
      "+-----+----+-------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, year, quarter, col, sum, round, count\n",
    "\n",
    "# Assuming SparkSession is already created and cleaned_df is preloaded DataFrame\n",
    "# Convert publicDate from string to date type\n",
    "cleaned_df = cleaned_df.withColumn(\"publicDate\", to_date(col(\"publicDate\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "# Extract Year and Quarter from publicDate\n",
    "cleaned_df = cleaned_df.withColumn(\"Year\", year(col(\"publicDate\")))\n",
    "cleaned_df = cleaned_df.withColumn(\"Quarter\", quarter(col(\"publicDate\")))\n",
    "\n",
    "# Group by Class, Year, and Quarter and perform aggregations\n",
    "grouped_df = cleaned_df.groupBy(\"Class\", \"Year\", \"Quarter\").agg(\n",
    "    round(sum(\"Score\"), 4).alias(\"Total Score\"),\n",
    "    count(\"id\").alias(\"Paper Count\")  # Count the number of papers per group\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710bfb81-f847-4f13-b777-96dafbec95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce the DataFrame to 1 partition to avoid multiple part files\n",
    "grouped_df.coalesce(1).write.csv(path=\"./nauture.csv\", mode=\"overwrite\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
